{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practica 5 Morfología y Extracción de Características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se presentan una serie de ejercicios de carácter calificable.\n",
    "\n",
    "<br> Deben realizarse en los grupos de trabajo asignados y subirse al GitHub respectivo </br>\n",
    "\n",
    "No es necesario concluir, pero deben presentarse las respuestas de forma <b> ordenada </b>\n",
    "\n",
    "## Fecha límite de entrega: Jueves 8 de agosto a media noche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.\n",
    "\n",
    "Lea la imagen \"res/jirafa.png\" y realice:\n",
    "\n",
    "1. Extracción de bordes mediante erosión y dilatación.\n",
    "2. Extracción de bordes mediante la función gradiente.\n",
    "3. Extracción de bordes mediante la operación XOR entre dilatación y erosión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.\n",
    "\n",
    "<br> Lea la imagen \"res/silueta.png\" y obsérvela cuidadosamente. </br>\n",
    "<br> Lea también, la imagen \"res/silueta2.png\" y repita el proceso. </br>\n",
    "<br> Las imágenes tienen dos tipos de ruido distintos colocados con una serie de cuidadosas operaciones hechas en paint </br>\n",
    "\n",
    "Utilice morfologías de  apertura y cierre (escogiendo la máscara adecuada) para eliminar el ruido sin afectar demasiado la silueta de la jirafa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.\n",
    "\n",
    "1. Lea la imagen \"res/jirafa.png\" en escala de grises.\n",
    "\n",
    "Realice un etiquetado de regiones escogiendo la máscara correcta (no necesariamente un rectángulo, prueba un disco o la identidad).\n",
    "\n",
    "<img src = \"res/etiq.png\">\n",
    "\n",
    "<center><i>Figura: Solución aproximada</i></center>\n",
    "\n",
    "Imprima el número de etiquetas (Debe ser 1)\n",
    "\n",
    "2. Ya que ha leido la imagen \"res/jirafa.png\" utilice el método de esqueletización de Zhang para obtener el esqueleto de ésta imagen (recuerde que es una imagen binaria)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No olvide revisar el Pipeline de segmentación que se encuentra en el notebook de la clase 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.\n",
    "\n",
    "Cree una imagen de ceros (np.zeros()) de 600x600, posteriormente un cuadrado de 100x100, cuyo <i>start</i> está en la coordenada [200,200] (Utilice la función rectangle de skimage, es un proceso análogo a dibujar la elipse)\n",
    "\n",
    "\n",
    "<img src = \"res/pis.png\">\n",
    "\n",
    "<center><i>Figura: Cuadrado</i></center>\n",
    "\n",
    "Una vez tenga la imagen anterior, realice los siguientes pasos (Debe realizar UN SOLO PLOT POR CADA NUMERAL listado a continuación)\n",
    "\n",
    "1. Plotee el cuadrado que creó, imprima el área y el perímetro respectivos.\n",
    "2. Imprima el cuadrado con el centroide, adicionalmente imprima las coordenadas del centroide.\n",
    "3. Imprima el cuadrado rodeado por el rectángulo más pequeño que lo rodea (si quiere puede mostrarlo con el centroide)\n",
    "4. Muestre las distancias respecto al contorno.\n",
    "5. Imprima el cuadrado con el centroide y el contorno, junto a la medida entre el contorno y el centroide.\n",
    "6. ¿Cuál es el diámetro equivalente? imprímalo.\n",
    "7. Imprima los momentos de HU y sus logaritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.\n",
    "\n",
    "Lea la imagen \"res/cancer.bmp\" y la máscara \"res/lesion.bmp\", utilice los algoritmos de extracción de características para encontrar los estadísticos de primer y segundo orden de esta imagen. Preste especial atención a este proceso individual, puesto que en el ejercicio guiado lo hará para varias imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio Guiado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este ejercicio es, mediante 5 imágenes de un dataset de melanomas, mostrar al estudiante cuál es el proceso de extracción de características.\n",
    "\n",
    "No duden en ir a la carpeta PH2Dataset para observar la información allí consignada, de igual forma las subcarpetas que contienen la imagen a estudiar y sus máscaras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leer estas utilidades, librerías a utilizar y funciones de lectura que necesitaremos para facilitar el trabajo posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from os.path import join, splitext, basename, abspath\n",
    "from os import listdir\n",
    "from skimage.io import imread\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "import math\n",
    "from skimage import morphology\n",
    "from skimage.measure import label, regionprops\n",
    "import cv2\n",
    "from skimage import measure\n",
    "from scipy.ndimage import rotate\n",
    "import math \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class MissingAttributeException(Exception):\n",
    "    def __init__(self, attribute):\n",
    "        super(MissingAttributeException, self).__init__(\n",
    "            'The <{}> attribute is not contained in the dataset'.format(attribute)\n",
    "        )\n",
    "\n",
    "\n",
    "class BaseDataset:\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    def __init__(self, dataset_path):\n",
    "        self.__dataset_path = abspath(dataset_path)\n",
    "        self.__image_list = self.load_dataset(self.__dataset_path)\n",
    "        self.__sample = self.__image_list\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_dataset(self, dataset_path):\n",
    "        '''\n",
    "        It must return a vector of dictionary in the followed way (keys with * are mandatory):\n",
    "        image_data = [\n",
    "                        {\n",
    "                            'image_filename': <* image filename>,\n",
    "                            'imageName': <* image name>,\n",
    "                            'ground_truth_filename': <ground_truth_filename>,\n",
    "                            'class': <class number the image belong to>,\n",
    "                            'labels': <vector of string labels associates with the image>\n",
    "                        },\n",
    "                        {...}\n",
    "                    ]\n",
    "        :param dataset_path: base path for the dataset\n",
    "        :return: a list of dictionaries containing the dataset information. One entry per image in the dataset\n",
    "        '''\n",
    "        return None\n",
    "\n",
    "    @abstractmethod\n",
    "    def read_data(self, filename):\n",
    "        return None\n",
    "\n",
    "    @abstractmethod\n",
    "    def has_class(self):\n",
    "        return False\n",
    "\n",
    "    @abstractmethod\n",
    "    def has_labels(self):\n",
    "        return False\n",
    "\n",
    "    @abstractmethod\n",
    "    def has_ground_truth(self):\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def image_names(self):\n",
    "        return [i['imageName'] for i in self.__sample]\n",
    "\n",
    "    @property\n",
    "    def num_images(self):\n",
    "        return len(self.__sample)\n",
    "\n",
    "    def reset_sample(self):\n",
    "        self.__sample = self.__image_list\n",
    "\n",
    "    def set_sample(self, **kwargs):\n",
    "        if 'percentage' in kwargs:\n",
    "            p = kwargs['percentage']\n",
    "            N = len(self.__image_list)\n",
    "            rn = np.random.rand(N)\n",
    "            j = np.argsort(rn)[0:int(np.floor(p * N))]\n",
    "            self.__sample = [self.__image_list[i] for i in j]\n",
    "        elif 'image_names' in kwargs:\n",
    "            i_names = kwargs['image_names']\n",
    "            self.__sample = [data for data in self.__image_list if data['imageName'] in i_names]\n",
    "        elif 'image_indices' in kwargs:\n",
    "            image_idxs = kwargs['image_indices']\n",
    "            self.__sample = [self.__image_list[i] for i in image_idxs]\n",
    "        else:\n",
    "            print('No samples was selected. All images will be used.')\n",
    "            self.reset_sample()\n",
    "\n",
    "    def exclude_from_sample(self, **kwargs):\n",
    "        if 'image_names' in kwargs:\n",
    "            i_names = kwargs['image_names']\n",
    "            self.__sample = [data for data in self.__sample if data['imageName'] not in i_names]\n",
    "        elif 'image_indices' in kwargs:\n",
    "            image_idxs = kwargs['image_indices']\n",
    "            self.__sample = [self.__sample[i] for i in range(len(self.__sample)) if i not in image_idxs]\n",
    "        else:\n",
    "            print('No elements were excluded from the sample.')\n",
    "\n",
    "    def get_image_data(self, idx_image):\n",
    "        current_image = self.__sample[idx_image]\n",
    "\n",
    "        if 'loaded' not in current_image or not current_image['loaded']:\n",
    "            current_image['data'] = self.read_data(current_image['image_filename'])\n",
    "            current_image['loaded'] = True\n",
    "\n",
    "        return current_image['data']\n",
    "\n",
    "    def get_ground_truth_data(self, idx_image):\n",
    "        current_image = self.__sample[idx_image]\n",
    "\n",
    "        if self.has_ground_truth():\n",
    "            if 'ground_truth_loaded' not in current_image or not current_image['ground_truth_loaded']:\n",
    "                current_image['ground_truth_data'] = self.read_data(current_image['ground_truth_filename'])\n",
    "                current_image['ground_truth_loaded'] = True\n",
    "\n",
    "            return current_image['ground_truth_data']\n",
    "        else:\n",
    "            raise MissingAttributeException('ground_truth_data')\n",
    "\n",
    "    def get_image_class(self, idx_image):\n",
    "        current_image = self.__sample[idx_image]\n",
    "\n",
    "        if self.has_class():\n",
    "            return current_image['class']\n",
    "        else:\n",
    "            raise MissingAttributeException('class')\n",
    "\n",
    "    def get_image_labels(self, idx_image):\n",
    "        current_image = self.__sample[idx_image]\n",
    "\n",
    "        if self.has_labels():\n",
    "            return current_image['labels']\n",
    "        else:\n",
    "            raise MissingAttributeException('labels')\n",
    "\n",
    "\n",
    "class MPEG7Dataset(BaseDataset):\n",
    "    \"\"\"\n",
    "    Concrete implementation of the MPEG-7 Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, basepath):\n",
    "        self.image_list = [{\n",
    "                               'image_filename': fn,\n",
    "                               'imageName': splitext(basename(fn))[0],\n",
    "                               'ground_truth_filename': None,\n",
    "                               'class': None,  # TODO,\n",
    "                               'labels': None\n",
    "                           } for fn in glob(join(basepath, 'MPEG7/original/*.gif'))]\n",
    "\n",
    "class PH2Dataset(BaseDataset):\n",
    "    \"\"\"\n",
    "    Concrete implementation of the MPEG-7 Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_path):\n",
    "        BaseDataset.__init__(self, base_path)\n",
    "\n",
    "    def load_dataset(self, dataset_path):\n",
    "        image_list = []\n",
    "        images_base_folder = join(dataset_path, 'PH2 Dataset images')\n",
    "        image_dirs = [f for f in listdir(images_base_folder) if not f.startswith('.')]\n",
    "\n",
    "        #Reads the info in the XLSX file\n",
    "        df = pd.read_excel(join(dataset_path, 'PH2_dataset.xlsx'))\n",
    "        classes = []\n",
    "        for i in range(len(image_dirs)):\n",
    "\n",
    "            cell_common_nevus = df.iloc[i + 11, 2]\n",
    "            cell_atypical_nevus = df.iloc[i + 11, 3]\n",
    "            cell_melanoma = df.iloc[i + 11, 4]\n",
    "\n",
    "            if cell_common_nevus == 'X':\n",
    "                image_class = 1\n",
    "            elif cell_atypical_nevus == 'X':\n",
    "                image_class = 2\n",
    "            else:\n",
    "                image_class = 3\n",
    "\n",
    "            classes.append({\n",
    "                'name': df.iloc[i + 11, 0],\n",
    "                'class': image_class\n",
    "            })\n",
    "\n",
    "        for image_folder_name in image_dirs:\n",
    "            filename = join(images_base_folder, image_folder_name, image_folder_name + '_Dermoscopic_Image',\n",
    "                            image_folder_name + '.bmp')\n",
    "            ground_truth_filename = join(images_base_folder, image_folder_name, image_folder_name + '_lesion',\n",
    "                                         image_folder_name + '_lesion.bmp')\n",
    "\n",
    "\n",
    "\n",
    "            #image class\n",
    "            results = list(filter(lambda all_classes: all_classes['name'] == image_folder_name, classes))\n",
    "            if len(results) > 0:\n",
    "                c = results[0]['class']\n",
    "            else:\n",
    "                c = 1\n",
    "\n",
    "            image_list.append({\n",
    "                'image_filename': filename,\n",
    "                'imageName': image_folder_name,\n",
    "                'ground_truth_filename': ground_truth_filename,\n",
    "                'class': c,\n",
    "                'labels': ['', ''] #TODO: llenar esto\n",
    "            })\n",
    "\n",
    "        return image_list\n",
    "\n",
    "    def read_data(self, filename):\n",
    "        return imread(filename)\n",
    "\n",
    "    def has_class(self):\n",
    "        return True\n",
    "\n",
    "    def has_labels(self):\n",
    "        return True\n",
    "\n",
    "    def has_ground_truth(self):\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_hsv(im):\n",
    "    return cv2.cvtColor(im, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "def rgb_to_lab(im):\n",
    "    return cv2.cvtColor(im, cv2.COLOR_RGB2LAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura del dataset\n",
    "\n",
    "Por cuestiones de portabilidad y velocidad de procesamiento, este ejercicio posee 5 imágenes asociadas al dataset. Vamos a leer el excel PH2Dataset y las imágenes. Si tienes algún problema con este paso, asegúrate de tener tu carpeta organizada de la siguiente manera:\n",
    "\n",
    "<img src = \"res/ejemplo.png\">\n",
    "\n",
    "Y dentro de la carpeta PH2Dataset:\n",
    "\n",
    "<img src = \"res/example.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PH2Dataset(\"PH2Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = dataset.load_dataset(\"PH2Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de las imágenes\n",
    "\n",
    "Recuerda que nuestro Dataset consta de información consignada en un archivo y de imágenes con su respectivo label que corresponde al ground truth. Corre este código para leer las imágenes dentro del Dataset. \n",
    "\n",
    "Tenemos 5 imágenes, por tanto si intentas hacer que idd>4, arrojará error. (¡pruebalo!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idd = 0\n",
    "image1 = dataset.read_data(images[idd][\"image_filename\"])\n",
    "image1_mask = dataset.read_data(images[idd][\"ground_truth_filename\"])\n",
    "mask_3c = np.zeros((image1.shape), np.uint8)\n",
    "mask_3c[:,:,0] = image1_mask\n",
    "mask_3c[:,:,1] = image1_mask\n",
    "mask_3c[:,:,2] = image1_mask\n",
    "image1 = image1 * (mask_3c > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase asociada a la imagen\n",
    "\n",
    "Cada imagen tiene una clase asociada que en algún paso de clasificación se intentará predecir, por ahora, varía \"idd\" y verifica la clase de las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[idd][\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones para extracción de características\n",
    "\n",
    "Es hora de extraer las características de las imágenes, como bien observaste con el ejercicio individual del melanoma, al multiplicarlo por la máscara asociada y aplicar algoritmos de extracción de estadísticos de primer y segundo orden pueden obtenerse una cantidad enorme de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lab_hsv_features(im, mask, features):\n",
    "    #La imagen de entrada debe estar en el espacio RGB\n",
    "    #Extraer el tamaño de la imagen de entrada y convertirla a LAB y HSV\n",
    "    shape = np.shape(im)\n",
    "    im_lab = rgb_to_lab(im)\n",
    "    im_hsv = rgb_to_hsv(im)\n",
    "    \n",
    "    #Definir los canales  por separado\n",
    "    s = im_hsv[:,:,1]\n",
    "    v = im_hsv[:,:,2]\n",
    "    \n",
    "    a = im_lab[:,:,1]\n",
    "    b = im_lab[:,:,2]\n",
    "    #Definir listas vacías de canales h,s,v\n",
    "    a_1 = []\n",
    "    b_1 = []\n",
    "    s_1 = []\n",
    "    v_1= []\n",
    "    \n",
    "    #Recorrer cada posición i,j de la matriz de la imagen de entrada\n",
    "    for i in range(shape[0]):\n",
    "        for j in range(shape[1]):\n",
    "            #Condicional, si la máscara en la posición i,j es un array verdadero añadir\n",
    "            #a cada canal del nuevo HSV el píxel en esta posición\n",
    "            if((mask[i][j] == np.array([True, True, True])).all() ):\n",
    "                s_1.append(s[i][j])\n",
    "                v_1.append(v[i][j])\n",
    "                a_1.append(a[i][j])\n",
    "                b_1.append(a[i][j])\n",
    "                \n",
    "    #Utilizar features para guardar los valores de media, desviación estándar, kurtosis y sesgo\n",
    "    #de cada uno de los canales h_1, s_1, v_1\n",
    "    features['s_mean'] = np.mean(s_1)\n",
    "    features['s_std'] = np.std(s_1)\n",
    "    features['s_kurtosis'] = kurtosis(s_1)\n",
    "    features['s_skew'] = skew(s_1)\n",
    "    features['v_kurtosis'] = kurtosis(v_1)\n",
    "    features['v_skew'] = skew(v_1)\n",
    "    features['v_mean'] = np.mean(v_1)\n",
    "    features['v_std'] = np.std(v_1)\n",
    "    features['lab_a_mean'] = np.mean(a_1)\n",
    "    features['lab_a_std'] = np.std(a_1)\n",
    "    features['lab_a_kurtosis'] = kurtosis(a_1)\n",
    "    features['lab_a_skew'] = skew(a_1)\n",
    "    features['lab_b_kurtosis'] = kurtosis(b_1)\n",
    "    features['lab_b_skew'] = skew(b_1)\n",
    "    features['lab_b_mean'] = np.mean(b_1)\n",
    "    features['lab_b_std'] = np.std(b_1)\n",
    "\n",
    "    return features\n",
    "\n",
    "def get_moments_hu(props, features):\n",
    "    moments_hu = props.moments_hu\n",
    "    moments_hu = np.sign(moments_hu) * np.log(np.abs(moments_hu))\n",
    "    features['hu0'] = moments_hu[0]\n",
    "    features['hu1'] = moments_hu[1]\n",
    "    features['hu2'] = moments_hu[2]\n",
    "    features['hu3'] = moments_hu[3]\n",
    "    features['hu4'] = moments_hu[4]\n",
    "    features['hu5'] = moments_hu[5]\n",
    "    features['hu6'] = moments_hu[6]\n",
    "    return features\n",
    "\n",
    "def get_features_perimeter(mask, features):\n",
    "    contours = measure.find_contours(mask, 0.8)\n",
    "    features['perimeter'] = contours[0].shape[0]\n",
    "    return features\n",
    "\n",
    "def get_features_area(props, features):\n",
    "    features['area'] = props.area\n",
    "    features['convex_area'] = props.convex_area\n",
    "    features['area_to_convex_ratio'] = props.area/props.convex_area\n",
    "    features['compacity'] = props.perimeter**2/props.area\n",
    "    features['roundness'] = 4*math.pi*props.area /(props.perimeter**2)\n",
    "    features['area_perimeter_ratio'] = props.area / props.perimeter\n",
    "    features['elongation'] = props.major_axis_length/props.minor_axis_length\n",
    "    features['major_axis_length'] = props.major_axis_length\n",
    "    features['minor_axis_length'] = props.minor_axis_length\n",
    "    features['solidity1'] = props.area/props.convex_area\n",
    "    features['solidity2'] = props.area / props.filled_area\n",
    "    return features\n",
    "\n",
    "#Definir función para extraer características del espacio RGB\n",
    "def get_rgb_features(im,mask, features):\n",
    "    #Crear una matriz del mismo tamaño de la imagen de entrada, leer los canales R,G,B y \n",
    "    #crear listas vacías donde se aplica la máscara\n",
    "    shape = np.shape(im)\n",
    "    r = im[:,:,0]\n",
    "    g = im[:,:,1]\n",
    "    b = im[:,:,2]\n",
    "    r_1 = []\n",
    "    g_1 = []\n",
    "    b_1 = []\n",
    "    #Recorrer las posiciones i,j de la matriz de la imagen de entrada\n",
    "    for i in range(shape[0]):\n",
    "        for j in range(shape[1]):\n",
    "            #Condicional, si la máscara en la posición i,j es un array de True, añadir\n",
    "            #a cada canal del nuevo espacio RGB el píxel en esta posición\n",
    "            if( (mask[i][j] == np.array([True, True, True])).all() ): \n",
    "                r_1.append(r[i][j])\n",
    "                g_1.append(g[i][j])\n",
    "                b_1.append(b[i][j])\n",
    "    #Utilizar features para guardar los valores de media, desv.estandar, kurtosis y sesgo\n",
    "    #de los canales r_1,g_1,b_1\n",
    "    features['r_mean'] = np.mean(r_1)\n",
    "    features['r_std'] = np.std(r_1)\n",
    "    features['r_kurtosis'] = kurtosis(r_1)\n",
    "    features['r_skew'] = skew(r_1)\n",
    "    features['g_mean'] = np.mean(g_1)\n",
    "    features['g_std'] = np.std(g_1)\n",
    "    features['b_kurtosis'] = kurtosis(b_1)\n",
    "    features['b_skew'] = skew(b_1)\n",
    "    features['b_mean'] = np.mean(b_1)\n",
    "    features['b_std'] = np.std(b_1)\n",
    "    features['g_kurtosis'] = kurtosis(g_1)\n",
    "    features['g_skew'] = skew(g_1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_pipeline(img, mask):\n",
    "    #Crear el diccionario para guardar las características\n",
    "    features = {}\n",
    "    label_img = label(mask)\n",
    "    props = regionprops(label_img)[0]\n",
    "    mask_3c = np.zeros((img.shape), np.uint8)\n",
    "    mask_3c[:,:,0] = mask\n",
    "    mask_3c[:,:,1] = mask\n",
    "    mask_3c[:,:,2] = mask\n",
    "    features = get_moments_hu(props, features)\n",
    "    features = get_features_area(props, features)\n",
    "    features = get_rgb_features(img,mask_3c,features)\n",
    "    features = get_lab_hsv_features(img,mask_3c,features)\n",
    "    features = get_features_perimeter(mask, features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraigamos las características de una sola imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_base = features_pipeline(image1, image1_mask > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realicemos un for loop para extraer las características de las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(features_base.keys())\n",
    "columns.append('class')\n",
    "df = pd.DataFrame(columns=columns)\n",
    "#Ir desde i hasta el # de datos del dataset PH2Dataset\n",
    "for i in range(5):\n",
    "    image = dataset.read_data(images[i][\"image_filename\"])\n",
    "    mask = dataset.read_data(images[i][\"ground_truth_filename\"])\n",
    "    mask_3c = np.zeros((image.shape), np.uint8)\n",
    "    mask_3c[:,:,0] = mask\n",
    "    mask_3c[:,:,1] = mask\n",
    "    mask_3c[:,:,2] = mask\n",
    "    image = image * (mask_3c > 0)\n",
    "    features = features_pipeline(image, mask > 0)\n",
    "    df.loc[i] = [features[feature] for feature in features_base.keys()]+[images[i][\"class\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Qué obtuvimos entonces?\n",
    "\n",
    "En este momento, si te fijas construimos un dataframe de pandas, llamado \"df\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"df\" contiene la información de las 46 características que extrajimos de las imágenes del pequeño dataset que construimos. Las otras dos columnas son el ID de cada fila(cada imagen, 0,1,2,3,4) y la clase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea con el código guiado:\n",
    "\n",
    "En la carpeta \"Tarea codigo guiado\" se encuentra una subcarpeta llamada \"IMD049\", debe copiarse esta subcarpeta a la carpeta \"PH2 Dataset images\".\n",
    "\n",
    "Esto en esencia es añadir un nuevo dato al Dataset.\n",
    "\n",
    "A continuación debe utilizarse el código guiado para generar un dataframe de pandas con 6 ID (0, 1, 2, 3, 4, 5) conteniendo el último dato añadido.\n",
    "\n",
    "Finalmente, guardar el dataframe \"df\" como un archivo .csv y subirlo en la misma carpeta que la tarea solucionada.\n",
    "\n",
    "## Este ejercicio es de carácter obligatorio."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
