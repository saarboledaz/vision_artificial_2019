{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Evaluación de Desempeño VA2019-01.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "eVSXUdJ_94mQ",
        "A1wcAktf94mn",
        "hh71vDtE94mz",
        "txn8yQeZ94nT",
        "V2ZzgrfJ94nt",
        "aaq6m-bO94oV",
        "V8eyKycR94ow",
        "EiiZsCzw94pO",
        "KyRPyThI94pb",
        "TfoBIPi594pj",
        "krbkCf8G94po",
        "Nc6Ntv1294qG",
        "7USHDvq094qX",
        "w7nMWxQh5q43",
        "50nOx2HX94qe",
        "dix_Ogv094qg",
        "HexuNRfP94qi",
        "pLM1TE3i94qk",
        "3m0lu0rG94qn",
        "fih6ewKr94rH",
        "YEOcme6794rQ",
        "jRYfxCh194r6",
        "6y7PO56Se0iS",
        "Nfh9mc-mmwBZ"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HA1JqhF94lm",
        "colab_type": "text"
      },
      "source": [
        "# Métodos de clasificación y evaluación de desempeño."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0faqNCi94lo",
        "colab_type": "text"
      },
      "source": [
        "Cualquier modelo de aprendizaje supervisado requiere una previa verificación antes de ser utilizado en el mundo real. \n",
        "\n",
        "La precisión de un modelo se mide con base en la función de costo.\n",
        "\n",
        "$$  L(Y, f(x))  $$ \n",
        "\n",
        "$L$ recibe el valor real $Y$ (dato considerado como verdadero) y el valor que el modelo $f$ predice con el dato de entrada $x$.\n",
        "\n",
        "Por tanto, el error de $L$ depende únicamente del dato de entrada $x$ en un modelo entrenado determinado. El objetivo es minimizar el error de $L$, sabiendo que ésta representa la diferencia entre el valor teórico y el predicho.\n",
        "\n",
        "$$ Err = E[ L(Y, f(x)) ]  $$\n",
        "\n",
        "$Err$ representa el error promedio para todos los datos $x$ y $E[]$ la esperanza calculada sobre estos valores obtenidos.\n",
        "\n",
        "Las funciones de costo/pérdida pueden ser diferentes, entre ellas el conocido error cuadrático medio (ECM).\n",
        "\n",
        "<center><img src= \"res/ecm.png\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LL5pzP8094lq",
        "colab_type": "text"
      },
      "source": [
        "# División de los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5AuuWC994ls",
        "colab_type": "text"
      },
      "source": [
        "En la mayoría de los casos, para todos los modelos de aprendizaje de máquina se dividen los datos en dos conjuntos, uno que sirve para entrenar el modelo y el otro para verificar los resultados del modelo ya entrenado, estos son denominados set de entrenamiento y set de pruebas (train and test sets).\n",
        "\n",
        "Los datos, usualmente vienen con el siguiente formato:\n",
        "\n",
        "$[X, Y]$ donde $X$ son las variables independientes (los datos de entrada), y $Y$ es la variable dependiente (lo que se quiere predecir).\n",
        "\n",
        "Una consideración muy importante al dividir los datos en varios conjuntos es mantener las proporciones del dataset original.\n",
        "\n",
        "Usualmente, la proporción que se deja entre el conjunto de entrenamiento y prueba es 80-20. El 80% de los datos para el conjunto de entrenamiento y el 20% restante para el de pruebas, este tipo de división suele hacerse cuando se cuentan con pocos datos (un par de decenas de miles).\n",
        "\n",
        "Debe tenerse en cuenta que si se trabaja con Big Data, el volumen de datos es mucho mayor y no hay problema al realizar proporciones del tipo 98% - 2%, dado que se tienen varios millones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTB4n2Gf94lt",
        "colab_type": "text"
      },
      "source": [
        "# Ejercicio practico."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cV4meiPJ94lv",
        "colab_type": "text"
      },
      "source": [
        "A continuación, se leerá un dataset de diabetes que se encuentra en la carpeta \"datos\", tal como puede apreciarse, éste es un archivo de tipo \"csv\", como el que usted creó en el ejercicio guiado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoNIHGyi94lx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Paquetes necesarios para la manipulación de los datos\n",
        "import pandas as pd\n",
        "from sklearn.metrics import auc\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split    \n",
        "from sklearn.metrics import precision_score, mean_squared_error, confusion_matrix, mean_absolute_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve\n",
        "import warnings\n",
        "from sklearn.svm import SVC,libsvm\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhNftXSg94l4",
        "colab_type": "text"
      },
      "source": [
        "Una vez leídos los paquetes necesarios para manipular los datos, entre ellos se encuentra pandas y sklearn, debe leerse el dataset de diabetes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIUM8Hm3-iY1",
        "colab_type": "code",
        "outputId": "8da5ab3e-8b8b-417d-c9a6-4fc67e46d13d",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 40
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-21848f54-74ed-4ccf-89e5-d9105d0e14d3\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-21848f54-74ed-4ccf-89e5-d9105d0e14d3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyWq16es94l6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "diabetes = pd.read_csv(\"diabetes.csv\", sep=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ow0-VmLY94mD",
        "colab_type": "text"
      },
      "source": [
        "Probemos que haya sido leído, imprimamos la información, para no utilizar espacio del notebook innecesariamente, solo será impresa la cola del dataset(si se quiere leer la parte superior, se utiliza \"head\")."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUULbAkM94mH",
        "colab_type": "code",
        "outputId": "c1f2d9a1-0f2c-4037-ca2b-8ec775507f46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#diabetes.head()\n",
        "diabetes.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>preg</th>\n",
              "      <th>plas</th>\n",
              "      <th>pres</th>\n",
              "      <th>skin</th>\n",
              "      <th>insu</th>\n",
              "      <th>mass</th>\n",
              "      <th>pedi</th>\n",
              "      <th>age</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>tested_negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "      <td>tested_negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>tested_negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "      <td>tested_positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "      <td>tested_negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     preg  plas  pres  skin  insu  mass   pedi  age            class\n",
              "763    10   101    76    48   180  32.9  0.171   63  tested_negative\n",
              "764     2   122    70    27     0  36.8  0.340   27  tested_negative\n",
              "765     5   121    72    23   112  26.2  0.245   30  tested_negative\n",
              "766     1   126    60     0     0  30.1  0.349   47  tested_positive\n",
              "767     1    93    70    31     0  30.4  0.315   23  tested_negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 265
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVSXUdJ_94mQ",
        "colab_type": "text"
      },
      "source": [
        "### Es importante conocer los datos con los que se está trabajando.\n",
        "\n",
        "Por tanto, es sugerible imprimir las columnas de nuestro dataset y adicionalmente, conocer las dimensiones del mismo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHnWgM1t94mS",
        "colab_type": "code",
        "outputId": "68410882-ba63-4d8d-fd77-8163dc56d6c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Nombres de las características de éste dataset\n",
        "diabetes.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age', 'class'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 266
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3fnrefA94mX",
        "colab_type": "code",
        "outputId": "1cb27d7e-28f8-4281-8392-e09f93d2a685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#(Número de datos, Número de características) ó (filas,columnas)\n",
        "diabetes.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 267
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6zS6tJd94mc",
        "colab_type": "text"
      },
      "source": [
        "Una de las columnas es la clase \"class\", es muy importante conocerla dado que corresponde a los datos Y del dataset (lo que busca predecirse a partir del conjunto de datos X y el modelo escogido)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNeKGbjG94me",
        "colab_type": "code",
        "outputId": "549e183a-ddcd-4784-a62a-bfc3992f84ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Mostrar las clases del dataset\n",
        "set(diabetes[\"class\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tested_negative', 'tested_positive'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoXfWN6L94ml",
        "colab_type": "text"
      },
      "source": [
        "En este caso específico, este dataset requiere clasificación de tipo binario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1wcAktf94mn",
        "colab_type": "text"
      },
      "source": [
        "## Normalización o escalamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbSGTpa994mq",
        "colab_type": "text"
      },
      "source": [
        "Una vez conocidos los datos, hay que realizar un proceso de escalamiento. Consiste en llevar todos los datos numéricos en el rango [0,1].\n",
        "\n",
        "Aunque existen múltiples scaler (MinMax, standard, etc) en este caso específico, escogeremos MinMax."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVN-1cWk94ms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Seleccionar el scaler\n",
        "scaler = MinMaxScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh71vDtE94mz",
        "colab_type": "text"
      },
      "source": [
        "## ¡La clase NO debe normalizarse!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtUujp7K94m0",
        "colab_type": "text"
      },
      "source": [
        "Por lo tanto, antes de normalizar los datos utilizando el scaler, separaremos los datos de entrada \"X\" y los datos reales \"Y\" o clase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9mS10q394m2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_diabetes = diabetes.drop(\"class\", axis=1)\n",
        "Y_diabetes = diabetes[\"class\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAVUsOl_94nC",
        "colab_type": "text"
      },
      "source": [
        "Para estar seguros, imprimamos X_diabetes y Y_diabetes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILk6hTk994nF",
        "colab_type": "code",
        "outputId": "dce70bbf-f7d9-4ed7-915f-4c1903abf591",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "X_diabetes.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>preg</th>\n",
              "      <th>plas</th>\n",
              "      <th>pres</th>\n",
              "      <th>skin</th>\n",
              "      <th>insu</th>\n",
              "      <th>mass</th>\n",
              "      <th>pedi</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   preg  plas  pres  skin  insu  mass   pedi  age\n",
              "0     6   148    72    35     0  33.6  0.627   50\n",
              "1     1    85    66    29     0  26.6  0.351   31\n",
              "2     8   183    64     0     0  23.3  0.672   32\n",
              "3     1    89    66    23    94  28.1  0.167   21\n",
              "4     0   137    40    35   168  43.1  2.288   33"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPK8oU_t94nO",
        "colab_type": "code",
        "outputId": "866f9067-3929-4ef8-8c68-3e73c2557cde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "Y_diabetes.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    tested_positive\n",
              "1    tested_negative\n",
              "2    tested_positive\n",
              "3    tested_negative\n",
              "4    tested_positive\n",
              "Name: class, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txn8yQeZ94nT",
        "colab_type": "text"
      },
      "source": [
        "## Ahora, se escalan los datos X_diabetes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B34XKrWz94nV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_diabetes_scaled = scaler.fit_transform(X_diabetes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmS6HeCf94na",
        "colab_type": "text"
      },
      "source": [
        "Una vez escalados, son convertidos en un array, volvamos esta información un dataframe de pandas y procedamos a trabajar con él."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cabQL0ip94nb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_diabetes_scaled = pd.DataFrame(X_diabetes_scaled, columns = X_diabetes.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqxbRgDs94ni",
        "colab_type": "text"
      },
      "source": [
        "Una vez más, imprimamos los datos para verificar que estén en el rango [0,1]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m42LWLHU94nj",
        "colab_type": "code",
        "outputId": "914c62eb-d338-4849-f7e7-d27842a3bb3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "X_diabetes_scaled.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>preg</th>\n",
              "      <th>plas</th>\n",
              "      <th>pres</th>\n",
              "      <th>skin</th>\n",
              "      <th>insu</th>\n",
              "      <th>mass</th>\n",
              "      <th>pedi</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.743719</td>\n",
              "      <td>0.590164</td>\n",
              "      <td>0.353535</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500745</td>\n",
              "      <td>0.234415</td>\n",
              "      <td>0.483333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.427136</td>\n",
              "      <td>0.540984</td>\n",
              "      <td>0.292929</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.396423</td>\n",
              "      <td>0.116567</td>\n",
              "      <td>0.166667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.470588</td>\n",
              "      <td>0.919598</td>\n",
              "      <td>0.524590</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.347243</td>\n",
              "      <td>0.253629</td>\n",
              "      <td>0.183333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.447236</td>\n",
              "      <td>0.540984</td>\n",
              "      <td>0.232323</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.418778</td>\n",
              "      <td>0.038002</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.688442</td>\n",
              "      <td>0.327869</td>\n",
              "      <td>0.353535</td>\n",
              "      <td>0.198582</td>\n",
              "      <td>0.642325</td>\n",
              "      <td>0.943638</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       preg      plas      pres  ...      mass      pedi       age\n",
              "0  0.352941  0.743719  0.590164  ...  0.500745  0.234415  0.483333\n",
              "1  0.058824  0.427136  0.540984  ...  0.396423  0.116567  0.166667\n",
              "2  0.470588  0.919598  0.524590  ...  0.347243  0.253629  0.183333\n",
              "3  0.058824  0.447236  0.540984  ...  0.418778  0.038002  0.000000\n",
              "4  0.000000  0.688442  0.327869  ...  0.642325  0.943638  0.200000\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 275
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2ZzgrfJ94nt",
        "colab_type": "text"
      },
      "source": [
        "# División en conjuntos de entrenamiento y pruebas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KUOr-Gg94nx",
        "colab_type": "text"
      },
      "source": [
        "La primera consideración que debe hacerse es, ¿Con cuántos datos cuento?, efectivamente tenemos 768 datos y 9 características distintas, por lo tanto, lo mejor es optar por una división tipo 80-20."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJbhUITa94nz",
        "colab_type": "text"
      },
      "source": [
        "Utilizando el dataframe obtenido tras normalizar (recordemos que podemos utilizar los mismos datos para Y dado que la clase no recibió ningún tipo de tratamiento), redefinimos X_diabetes & Y_diabetes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oIqcu0q94n0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Antes de realizar una división 80-20, definir los conjuntos X & Y.\n",
        "\n",
        "X_diabetes = X_diabetes_scaled\n",
        "Y_diabetes = diabetes[\"class\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGeZRRrN94oC",
        "colab_type": "text"
      },
      "source": [
        "Verificar que tengan el mismo numero de filas es importante.\n",
        "\n",
        "También es sugerible imprimir X_diabetes & Y_diabetes en caso de no saber si están correctos los conjuntos de trabajo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMl2mtSL94oF",
        "colab_type": "code",
        "outputId": "7eeb3665-d405-4963-e2ef-fd88812a3427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if X_diabetes.shape[0] == Y_diabetes.shape[0]:\n",
        "    print(\"El número de filas coinciden, ¡Es correcto!\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El número de filas coinciden, ¡Es correcto!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U01-fJlZ94oM",
        "colab_type": "text"
      },
      "source": [
        "Finalmente, debe realizarse la división de los datos, utilizando la función \"split\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgAQ9g-F94oN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_diabetes, X_test_diabetes, y_train_diabetes, y_test_diabetes = train_test_split(X_diabetes, Y_diabetes, test_size=0.20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTAuOq_994oS",
        "colab_type": "text"
      },
      "source": [
        "Nótese que el \"test_size\" es 0.20, lo que coincide con la teoría.\n",
        "\n",
        "Por otro lado, esta función le da valores de prueba y entrenamiento distintos cada vez que el código es utilizado, por lo tanto, no debe sorprenderse si hay variaciones en los conjuntos, lo que se mantendrá constante es la proporción entre éstos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaq6m-bO94oV",
        "colab_type": "text"
      },
      "source": [
        "# Modelos de clasificación.\n",
        "\n",
        "Tal como se sugiere, el primer modelo de clasificación que se utilizará será la Regresión Logística.\n",
        "\n",
        "Posteriormente se observará la matriz de confusión asociada y las métricas derivadas de ésta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24PiZnRi94oW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Regresión Logística con sklearn\n",
        "regresion_logistica = linear_model.LogisticRegression()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSlo1Xbi94oa",
        "colab_type": "text"
      },
      "source": [
        "Ahora, ajustemos los datos al modelo. Nótese que se utilizan los conjuntos X e Y de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWhzoku-94oc",
        "colab_type": "code",
        "outputId": "43c36155-8e25-48ad-ff8d-44097c6252c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "regresion_logistica.fit(X_train_diabetes, y_train_diabetes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFh7Ug8H94oh",
        "colab_type": "text"
      },
      "source": [
        "Una vez ajustado el modelo, observemos los resultados obtenidos.\n",
        "\n",
        "Esta primer pincelada puede darse reportando el <i><b> error de entrenamiento </b></i> y el <i><b> error de pruebas. </b></i>\n",
        "\n",
        "Para ello, realizaremos predicciones sobre el conjunto de pruebas(X_test_diabetes) y entrenamiento (X_train_diabetes) y calcularemos su \"accuracy_score\" respecto de los conjuntos de entrenamiento y prueba del conjunto Y (datos reales)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SXEQ5bP94ok",
        "colab_type": "code",
        "outputId": "df6c307b-3286-4280-885c-d78f267acb9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred_train = regresion_logistica.predict(X_train_diabetes)\n",
        "efectividad_entrenamiento = accuracy_score(y_train_diabetes, y_pred_train)\n",
        "print(\"1 - Error de entrenamiento = \" + str(efectividad_entrenamiento))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 - Error de entrenamiento = 0.7719869706840391\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKRKbXrT94op",
        "colab_type": "code",
        "outputId": "e6a3e924-a6cc-45a2-e43a-a1fd2a00c88f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred_test = regresion_logistica.predict(X_test_diabetes)\n",
        "efectividad_pruebas = accuracy_score(y_test_diabetes, y_pred_test)\n",
        "print(\"1 - Error de pruebas: \" + str(efectividad_pruebas))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 - Error de pruebas: 0.7467532467532467\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C_KG1N894ou",
        "colab_type": "text"
      },
      "source": [
        "¿El modelo es un buen clasificador? ¿Esta sobre ajustado, bien o subajustado?\n",
        "\n",
        "R/ Usualmento los clasificadores que se encuentran el los papers tienen una efectividad un poco más alta, posiblemente se debe a que en estos, los procesos anteriores suele ser un poco más rigurosos. Aun así, la precisión no es mala, es un buen clasificador.\n",
        "Si estuviera sobreajustado debería haber tenido una precisión mucho más alta en alguna de las predicciones, no está sobreajustado ni subajustado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8eyKycR94ow",
        "colab_type": "text"
      },
      "source": [
        "# Matriz de confusión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucse1ESP94oy",
        "colab_type": "text"
      },
      "source": [
        "Ahora, se realizará la implementación de la matriz de confusión del modelo de Regresión Logística que se planteó con anterioridad.\n",
        "\n",
        "Nótese que ésta visualización permite encontrar métricas estadísticas y matemáticas para medir el desempeño del modelo, al mismo tiempo que deja ver si el éste está confundiendo una clase con otra.\n",
        "\n",
        "No necesariamente es de carácter binario, por lo cual es flexible a distintos tipos de clasificación.\n",
        "\n",
        "Es una comparación entre valores reales y valores predichos.\n",
        "\n",
        "<center> <img src = \"res/matriz.png\"> </center>\n",
        "\n",
        "A continuación, se utiliza \"confusion_matrix\" de sklearn.metrics para reportar esta información."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XGygNXI94o1",
        "colab_type": "code",
        "outputId": "ff67136c-e10f-4981-e4ab-0d5e177c483e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "matriz_confusion = confusion_matrix(y_test_diabetes, y_pred_test, labels=[\"tested_negative\", \"tested_positive\"])\n",
        "\n",
        "# Para mostrar de mejor forma la matriz\n",
        "table = pd.DataFrame(matriz_confusion)\n",
        "table.columns = [\"tested_negative\", \"tested_positive\"]\n",
        "table.index = [\"tested_negative\", \"tested_positive\"]\n",
        "print(table)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 tested_negative  tested_positive\n",
            "tested_negative               90                6\n",
            "tested_positive               33               25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63h4FhKb94o_",
        "colab_type": "text"
      },
      "source": [
        "Como puede observarse, este modelo presenta un problema con el dataset, dado que en 31 casos donde el paciente si sufre la enfermedad, los clasifica como negativos.\n",
        "\n",
        "A continuación se pueden describir las métricas vistas en clase, especialmente útiles cuando los datos estan desbalanceados. \n",
        "\n",
        "Los Falsos Positivos(FP), Falsos Negativos (FN), Verdaderos Positivos (VP) y Verdaderos Negativos (VN), que adquieren sentido cuando se trata de un problema de clasificación binaria."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQF0cUcZ94pD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VN, FP, FN, VP = matriz_confusion.ravel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVPvWHbq94pI",
        "colab_type": "text"
      },
      "source": [
        "Pueden imprimirse los valores correspondientes a VN, FP, FN y VP para corroborar que la información sea correcta en éstos. O bien, entender a qué corresponden."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKyMBOAJEmhp",
        "colab_type": "code",
        "outputId": "767fb5b4-e91f-4ea9-ea68-f19908a3015d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(VN, FP, FN, VP)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90 6 33 25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsuW1g7H94pL",
        "colab_type": "text"
      },
      "source": [
        "# Métricas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiiZsCzw94pO",
        "colab_type": "text"
      },
      "source": [
        "### Precisión del modelo:\n",
        "\n",
        "$$P = \\frac{VerdaderoPositivo}{VerdaderoPositivo + FalsoPositivo}$$\n",
        "\n",
        "Probabilidad de que el modelo no marque como positivo, una muestra negativo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TnDd2ld94pS",
        "colab_type": "code",
        "outputId": "a56c7a9b-43c9-4f77-ca6e-fb46b49bf65d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "P = VP/(VP+FP)\n",
        "print(\"La precisión del modelo es: \" + str(P))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "La precisión del modelo es: 0.8064516129032258\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyRPyThI94pb",
        "colab_type": "text"
      },
      "source": [
        "### Sensibilidad(Recall) del modelo:\n",
        "\n",
        "$$R = \\frac{VerdaderoPositivo}{VerdaderoPositivo + FalsoNegativo}$$\n",
        "\n",
        "Capacidad del modelo de encontrar los valores positivos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s8YP-s494pd",
        "colab_type": "code",
        "outputId": "e5c53f59-ed04-4cfb-ac9a-768462bac495",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "R = VP/(VP+FN)\n",
        "print(\"La sensibilidad del modelo es: \" + str(R))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "La sensibilidad del modelo es: 0.43103448275862066\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfoBIPi594pj",
        "colab_type": "text"
      },
      "source": [
        "### Especificidad del modelo:\n",
        "\n",
        "$$E = \\frac{VerdaderoNegativo}{VerdaderoNegativo + FalsoPositivo}$$\n",
        "\n",
        "Capacidad del modelo de encontrar elementos negativos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_LmiNn594pk",
        "colab_type": "code",
        "outputId": "1c7a0e5f-e0e7-4a0e-d8ae-e37d7e242baa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "E = VN/(VN+FP)\n",
        "print(\"La especificidad del modelo es: \" + str(E))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "La especificidad del modelo es: 0.9375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krbkCf8G94po",
        "colab_type": "text"
      },
      "source": [
        "### F1 Score:\n",
        "\n",
        "\n",
        "\n",
        "$$F1\\_score = \\frac{2 * P * R}{P + R}$$\n",
        "\n",
        "Promedio entre precisión y sensibilidad, que da igual importancia a ambos valores.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjoUiLe194pp",
        "colab_type": "code",
        "outputId": "59c664d4-9e0c-48ba-a256-34e9affa0da6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "F = (2*P*R)/(P+R)\n",
        "print(\"El F1-Score del modelo es: \" + str(F))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El F1-Score del modelo es: 0.5617977528089887\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAaGNwp-94pt",
        "colab_type": "text"
      },
      "source": [
        "## El caso multi-clase.\n",
        "\n",
        "Si se encuentra un problema multi-clase, pueden utilizarse estas versiones del código.\n",
        "\n",
        "precision_score, recall_score, fbeta_score de la librería sklearn.metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhUk1ZWE94py",
        "colab_type": "text"
      },
      "source": [
        "### AUC (Area Under Curve)\n",
        "\n",
        "Para modelos de clasificación binaria únicamente, como la Regresión Logística, puede definirse un threshold, tal que diferencie valores verdaderos o falsos.\n",
        "\n",
        "El umbral es muy importante, si es muy cercano a cero (como 0.1) el sistema tiende a clasificar todo como positivo, si es cercano a 1 (como 0.9) los objetos clasificados serán casi todos negativos y finalmente, si el umbral es 0.5 tenderá a clasificar todo por igual.\n",
        "\n",
        "Así mismo, para la métrica AUC se busca obtener valores asociados a la Sensibilidad $S$ y la Especificidad $E$, posteriormente construir el gráfico $S$ vs $1-P$.\n",
        "\n",
        "A continuación, se implementa el AUC para el modelo Regresión Logística aplicado al dataset de diabetes normalizado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE6BCdZP94pz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculo del valor x para el caso de la regresión logistica\n",
        "y_score = regresion_logistica.decision_function(X_test_diabetes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONRndMPn94p3",
        "colab_type": "code",
        "outputId": "3006f5ae-f58b-483e-8f2c-1f151eabc8e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_test_diabetes, y_score, pos_label=\"tested_positive\")\n",
        "print(\"Los thresholds son: \\n\")\n",
        "print(thresholds)\n",
        "print(\"Los valores de sensibilidad son: \\n\")\n",
        "print(tpr) # imprimir la sensibilidad\n",
        "print(\"Los valores de especificidad son: \\n\")\n",
        "print(1-fpr) # imprimir la especificidad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Los thresholds son: \n",
            "\n",
            "[ 2.76459732  1.76459732  1.75119783  1.30108273  1.03107895  0.98328783\n",
            "  0.44596865  0.43313533  0.31452451  0.3043114   0.13680109  0.0981773\n",
            "  0.09688686  0.0957263  -0.04640425 -0.14306039 -0.25017341 -0.27007579\n",
            " -0.28517041 -0.33878204 -0.35398377 -0.37883887 -0.44768671 -0.45344099\n",
            " -0.48327231 -0.54374671 -0.56767788 -0.57021951 -0.59822066 -0.64540523\n",
            " -0.65735808 -0.65999197 -0.66201757 -0.67943116 -0.7070431  -0.75812738\n",
            " -0.7620008  -0.77281419 -0.77942729 -0.81245723 -0.83775273 -0.86313381\n",
            " -0.90743446 -0.93443918 -0.97450433 -1.03236849 -1.06330947 -1.16944358\n",
            " -1.19026622 -1.19064386 -1.2064983  -1.2862771  -1.30185381 -1.60680389\n",
            " -1.61619423 -2.41088024 -2.41521399 -2.67044257]\n",
            "Los valores de sensibilidad son: \n",
            "\n",
            "[0.         0.01724138 0.03448276 0.03448276 0.0862069  0.0862069\n",
            " 0.15517241 0.15517241 0.25862069 0.25862069 0.31034483 0.31034483\n",
            " 0.32758621 0.32758621 0.48275862 0.48275862 0.51724138 0.51724138\n",
            " 0.53448276 0.53448276 0.55172414 0.55172414 0.60344828 0.60344828\n",
            " 0.65517241 0.65517241 0.67241379 0.67241379 0.70689655 0.70689655\n",
            " 0.72413793 0.72413793 0.74137931 0.74137931 0.75862069 0.75862069\n",
            " 0.77586207 0.77586207 0.79310345 0.79310345 0.82758621 0.82758621\n",
            " 0.84482759 0.84482759 0.87931034 0.87931034 0.89655172 0.89655172\n",
            " 0.9137931  0.9137931  0.93103448 0.93103448 0.96551724 0.96551724\n",
            " 0.98275862 0.98275862 1.         1.        ]\n",
            "Los valores de especificidad son: \n",
            "\n",
            "[1.         1.         1.         0.98958333 0.98958333 0.97916667\n",
            " 0.97916667 0.96875    0.96875    0.95833333 0.95833333 0.94791667\n",
            " 0.94791667 0.9375     0.9375     0.90625    0.90625    0.88541667\n",
            " 0.88541667 0.86458333 0.86458333 0.84375    0.84375    0.83333333\n",
            " 0.83333333 0.8125     0.8125     0.80208333 0.80208333 0.76041667\n",
            " 0.76041667 0.75       0.75       0.71875    0.71875    0.69791667\n",
            " 0.69791667 0.6875     0.6875     0.65625    0.65625    0.63541667\n",
            " 0.63541667 0.625      0.625      0.60416667 0.60416667 0.52083333\n",
            " 0.52083333 0.51041667 0.51041667 0.39583333 0.39583333 0.21875\n",
            " 0.21875    0.02083333 0.02083333 0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcAKfxpG94p7",
        "colab_type": "text"
      },
      "source": [
        "En el código anterior, se calcula varios valores de umbral (thresholds), cada uno acompañado de la sensibilidad (tpr) y el valor de 1-especificidad (fpr) que arrojaría la matriz de confusión de ese umbral."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxxEBekz94p8",
        "colab_type": "text"
      },
      "source": [
        "### Finalmente, se muestra la curva ROC y la comparación con la peor configuración posible existente, con matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHCxIzXI94p-",
        "colab_type": "code",
        "outputId": "3eebc098-9491-411b-fd2e-6534e9a28758",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "plt.plot(fpr, tpr)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('1 - Especificidad')\n",
        "plt.ylabel('Sensibilidad')\n",
        "plt.title('AUC')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'AUC')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 292
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nc6Ntv1294qG",
        "colab_type": "text"
      },
      "source": [
        "Ahora, el objetivo es calcular el AUC de la curva ROC, área que representa una medida de qué tan bueno o malo es el modelo estudiado. Entre mayor sea(cercano a 1), mucho mejor será el modelo.\n",
        "\n",
        "### Nota: \n",
        "Si un modelo se acerca a la linea punteada(AUC cercano a 0), significa que es un <i><b>MUY MAL</b></i> modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3SenzJX94qI",
        "colab_type": "code",
        "outputId": "dfbd0914-214b-490e-8feb-337439c5bcdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "auc2 = auc(fpr, tpr)\n",
        "print(\"El área bajo la curva del modelo es: \" + str(auc2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El área bajo la curva del modelo es: 0.8180675287356322\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvK589Pf94qV",
        "colab_type": "text"
      },
      "source": [
        "Si se tuviera otro modelo distinto de clasificación binaria, podría compararse con el modelo de Regresión Logística, calculando sus AUC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7USHDvq094qX",
        "colab_type": "text"
      },
      "source": [
        "## Evaluación de modelos de regresión.\n",
        "\n",
        "Este tipo de evaluación, es distinta dado que se lidia con una variable que puede tomar infinitos valores.\n",
        "\n",
        "Una medida fácil de comprender, se conoce como MAE (Mean Absolute Error), o promedio de errores.\n",
        "\n",
        "$$ MAE = \\frac{1}{n} \\sum_{i=1}^{n}|Y_{predicho} - Y_{real}| $$\n",
        "\n",
        "El $MAE$ da un primer pincelazo y permite saber qué tan bueno es el modelo, si $MAE = 0$, significa que el ajuste del modelo es perfecto a los datos.\n",
        "\n",
        "Por otro lado, el error cuadrático medio $MSE$, promedio de errores al cuadrado, cuando es pequeño indica un buen ajuste del modelo y entre más alto sea, será peor el ajuste, respectivamente.\n",
        "\n",
        "$$ MSE = \\frac{1}{n} \\sum_{i=1}^{n}(Y_{predicho} - Y_{real})^2 $$\n",
        "\n",
        "### Nota:\n",
        "\n",
        "Debe tenerse cuidado con el análisis de los valores obtenidos en el MSE y el MAE, dependiendo de los datos, los valores pueden ser grandes o pequeños.\n",
        "\n",
        "Un ejemplo, es, supongamos que obtenemos un $MSE = 8$, antes de decidir si el modelo ajusta correctamente o no, debe estudiarse el tipo de dato que se está utilizando en el dataset y cuál es su rango de valores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQIBT_B594qd",
        "colab_type": "text"
      },
      "source": [
        "# Tarea:\n",
        "\n",
        "Implemente, una máquina de soporte vectorial (SVM) y utilícela sobre el mismo dataset. \n",
        "\n",
        "Compare los resultados mediante el área bajo la curva entre el modelo SVM y la regresión logística implementada en el notebook.\n",
        "\n",
        "Recuerde que debe utilizar los mismos conjuntos de datos para ambos modelos(recuerde que split entrega la distribución respetando la proporción que escoja el usuario, pero de forma aleatoria con los datos)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7nMWxQh5q43",
        "colab_type": "text"
      },
      "source": [
        "# Solución Tarea SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6uj_-c257IU",
        "colab_type": "text"
      },
      "source": [
        "### Definición del SVM \n",
        "\n",
        "Se define el SVM que utilizaresmos y se ajustan los datos de entrenamiento al modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqWRfPDk5_Fs",
        "colab_type": "code",
        "outputId": "6d421609-7119-4902-fd5d-92f9a007804b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "Maq_soporte_vec = SVC(kernel='linear')\n",
        "Maq_soporte_vec.fit(X_train_diabetes, y_train_diabetes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
              "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
              "    shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 294
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMtKJoIs-Z5Z",
        "colab_type": "text"
      },
      "source": [
        "Una vez ajustado el modelo, observemos los resultados obtenidos.\n",
        "\n",
        "Realizaremos predicciones sobre el conjunto de pruebas(X_test_diabetes) y entrenamiento (X_train_diabetes) y calcularemos su \"accuracy_score\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpqPhUTF9iFs",
        "colab_type": "code",
        "outputId": "e34a9c7c-0bba-41d9-e353-b12c01d05ebe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred_trainSVM = Maq_soporte_vec.predict(X_train_diabetes)\n",
        "efectividad_entrenamientoSVM = accuracy_score(y_train_diabetes, y_pred_trainSVM)\n",
        "print(\"Precisión de entrenamiento = \" + str(efectividad_entrenamientoSVM))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precisión de entrenamiento = 0.7801302931596091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCTFiEt8_5mk",
        "colab_type": "code",
        "outputId": "4addc6ed-4cd8-4e31-fe3f-59f96d533fc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred_testSVM = Maq_soporte_vec.predict(X_test_diabetes)\n",
        "efectividad_pruebasSVM = accuracy_score(y_test_diabetes, y_pred_testSVM)\n",
        "print(\"Precisión de pruebas: \" + str(efectividad_pruebasSVM))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precisión de pruebas: 0.7402597402597403\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vg5fJ6QFMrf",
        "colab_type": "text"
      },
      "source": [
        "Calculamos el AUC del modelo\n",
        "\n",
        "Para la métrica AUC se busca obtener valores asociados a la Sensibilidad $S$ y la Especificidad $E$, posteriormente construir el gráfico $S$ vs $1-P$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCf3RmUuFQFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cálculo del score para el Support Vector Machine\n",
        "y_scoreSVM = Maq_soporte_vec.decision_function(X_test_diabetes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NezXb6APHPwl",
        "colab_type": "code",
        "outputId": "7cc3d771-316c-41dd-a0eb-200c1ffc34a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_test_diabetes, y_scoreSVM, pos_label=\"tested_positive\")\n",
        "print(\"Los thresholds son: \\n\")\n",
        "print(thresholds)\n",
        "print(\"Los valores de sensibilidad son: \\n\")\n",
        "print(tpr) # imprimir la sensibilidad\n",
        "print(\"Los valores de especificidad son: \\n\")\n",
        "print(1-fpr) # imprimir la especificidad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Los thresholds son: \n",
            "\n",
            "[ 3.5432278   2.5432278   1.79526424  1.60348471  1.28428369  1.27451176\n",
            "  0.89539649  0.82315168  0.40479952  0.39634944  0.20150262  0.14563413\n",
            " -0.00541123 -0.00779071 -0.0479876  -0.07008842 -0.09444153 -0.21706003\n",
            " -0.25541432 -0.25694244 -0.34235369 -0.36095843 -0.40373699 -0.41983202\n",
            " -0.51303543 -0.55432286 -0.55607359 -0.56929174 -0.57854951 -0.61450984\n",
            " -0.62574094 -0.87275785 -0.88048898 -0.90913208 -1.01857498 -1.06337646\n",
            " -1.0901299  -1.21230051 -1.22537606 -1.27068155 -1.29584538 -1.63765661\n",
            " -1.65055207 -2.01873307 -2.05220295 -2.74501858 -2.86844729 -3.15812604]\n",
            "Los valores de sensibilidad son: \n",
            "\n",
            "[0.         0.01724138 0.05172414 0.05172414 0.06896552 0.06896552\n",
            " 0.13793103 0.13793103 0.25862069 0.25862069 0.37931034 0.37931034\n",
            " 0.43103448 0.43103448 0.46551724 0.46551724 0.48275862 0.48275862\n",
            " 0.51724138 0.51724138 0.63793103 0.63793103 0.67241379 0.67241379\n",
            " 0.75862069 0.75862069 0.77586207 0.77586207 0.79310345 0.79310345\n",
            " 0.81034483 0.81034483 0.82758621 0.82758621 0.87931034 0.87931034\n",
            " 0.9137931  0.9137931  0.93103448 0.93103448 0.94827586 0.94827586\n",
            " 0.96551724 0.96551724 0.98275862 0.98275862 1.         1.        ]\n",
            "Los valores de especificidad son: \n",
            "\n",
            "[1.         1.         1.         0.98958333 0.98958333 0.97916667\n",
            " 0.97916667 0.96875    0.96875    0.95833333 0.95833333 0.9375\n",
            " 0.9375     0.92708333 0.92708333 0.91666667 0.91666667 0.875\n",
            " 0.875      0.86458333 0.86458333 0.84375    0.84375    0.83333333\n",
            " 0.83333333 0.79166667 0.79166667 0.78125    0.78125    0.72916667\n",
            " 0.72916667 0.625      0.625      0.61458333 0.61458333 0.57291667\n",
            " 0.57291667 0.45833333 0.45833333 0.42708333 0.42708333 0.21875\n",
            " 0.21875    0.07291667 0.07291667 0.01041667 0.01041667 0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLBdlbUKIMC-",
        "colab_type": "code",
        "outputId": "ec89e027-65db-42da-d4bb-61e0db99a755",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "plt.plot(fpr, tpr)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('1 - Especificidad')\n",
        "plt.ylabel('Sensibilidad')\n",
        "plt.title('AUC')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'AUC')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 299
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hhzrxxTIaQ0",
        "colab_type": "code",
        "outputId": "22c79b8e-2a37-4d55-c12e-02bf60802d03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"El área bajo la curva del modelo es: \")\n",
        "auc(fpr, tpr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El área bajo la curva del modelo es: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8230962643678161"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 300
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hu3FEuy3S7f4",
        "colab_type": "text"
      },
      "source": [
        "### Comparación de resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCynYv8_S21O",
        "colab_type": "text"
      },
      "source": [
        "Comparado con el método de regresión logística, no se puede decir que un método sea mejor que otro, porque en este caso de ejecución, la diferencia fue muy pequeña; para el SVM el AUC fue de 0.8230962643678161, mientras que para la regresión logística el AUC fue de 0.8180675287356322. \n",
        "Se usaron subconjuntos idénticos del mismo dataset para las pruebas. Es posible que para una escojencia de los conjuntos de entrenamiento y prueba diferentes, haya una diferencia importante"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50nOx2HX94qe",
        "colab_type": "text"
      },
      "source": [
        "# Introducción al Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtTbmCMb94qf",
        "colab_type": "text"
      },
      "source": [
        "El <b> Machine Learning </b> o <b> aprendizaje de máquina </b>, es una disciplina científica del ámbito de la Inteligencia Artificial, que desarrolla y experimenta sistemas que \"aprenden\" de forma automática.\n",
        "\n",
        "En este contexto, el \"aprendizaje\", quiere decir la identificación de patrones complejos en <i> millones de datos </i>.\n",
        "    \n",
        "Para entender un poco, qué aprende una máquina, realicemos esta analogía.\n",
        "\n",
        "Clásicamente, se desarrolla este tipo de trabajo en programación:\n",
        "\n",
        "$$Salida = Entrada + Algoritmo$$\n",
        "\n",
        "Recordemos que el dataset, viene de la forma $[x,Y]$, y por tanto $x$ representa el dato de entrada e $Y$ el dato de salida (que se considera verdadero). Por lo tanto, el \"dato\" desconocido en nuestra ecuación, es el algoritmo.\n",
        "\n",
        "Bajo este planteamiento:\n",
        "\n",
        "$$Algoritmo = Entrada + Salida$$\n",
        "\n",
        "Este es el paradigma de estudio.\n",
        "\n",
        "<center> <img src=\"res/ml.jpg\" style=\"width:500px;height:450px;\"> </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dix_Ogv094qg",
        "colab_type": "text"
      },
      "source": [
        "# ¿Cómo podemos realizar Machine Learning?\n",
        "\n",
        "En este notebook, se utiliza Keras, aunque también puede hacerse con TensorFlow.\n",
        "\n",
        "La documentación que puede encontrarse esta en la página oficial de keras:\n",
        "\n",
        "https://keras.io\n",
        "\n",
        "También pueden realizarse numerosos tutoriales en la siguiente página:\n",
        "\n",
        "https://machinelearningmastery.com\n",
        "\n",
        "Sin olvidar los cursos que ofrecen plataformas virtuales como Coursera.\n",
        "\n",
        "## Sin más, vamos a crear nuestra primera red neuronal con Keras en un tutorial muy simple."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HexuNRfP94qi",
        "colab_type": "text"
      },
      "source": [
        "# Nuestra primera red neuronal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLM1TE3i94qk",
        "colab_type": "text"
      },
      "source": [
        "## 1. Lectura de datos\n",
        "\n",
        "Antes de comenzar un ejercicio de clasificación, debemos conocer qué vamos a clasificar.\n",
        "\n",
        "Por lo tanto el primer paso es cargar el dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3m0lu0rG94qn",
        "colab_type": "text"
      },
      "source": [
        "### Es muy probable que importar librerías arroje problemas, recuerden instalar los paquetes de keras y tensorflow en anaconda."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbZ7Px-Z94qo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importar librerías\n",
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB1tImM694qu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = loadtxt('pima-indians-diabetes.csv', delimiter=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isxFaPwP94q4",
        "colab_type": "code",
        "outputId": "5961a23e-d952-4204-ef86-c167107c282d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "dataset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 310
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kegwpnBM94q-",
        "colab_type": "code",
        "outputId": "d4439210-1704-4691-8d10-41f6e8dbec23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 311
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fih6ewKr94rH",
        "colab_type": "text"
      },
      "source": [
        "Este dataset tiene una visualización distinta al dataset de diabetes en pandas que se mostró anteriormente. Los datos no siempre se encuentran en un solo formato, es parte del reto trabajar con estas variaciones.\n",
        "\n",
        "## La última columna, representa la clase. Separemos los conjuntos X e Y, y posteriormente veamos si la clase es binaria."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOTV5wNy94rI",
        "colab_type": "code",
        "outputId": "058b3d3a-1fb6-4bea-ea9f-b9d3fdff3a72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "X = dataset[:,0:8]\n",
        "y = dataset[:,8]\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X1WvVTS94rO",
        "colab_type": "text"
      },
      "source": [
        "Si ejecutamos la instrucción print(y), se observa que es tipo binario. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEOcme6794rQ",
        "colab_type": "text"
      },
      "source": [
        "# 2. Keras\n",
        "\n",
        "Para construir una red neuronal en Keras, debe realizarse un modelo secuencial de \"layers\" (también llamados capas), un \"layer\" es un conjunto de neuronas que poseen una función de activación y unos pesos que ajustar.\n",
        "\n",
        "¿Cómo sabemos cuál es el mejor modelo para nuestro dataset?\n",
        "\n",
        "Tenemos muy pocos datos, no es sugerible una arquitectura con muchas neuronas, en este caso particular, escojamos 3 layers totalmente conectados.\n",
        "\n",
        "<center><img src = \"res/neu.jpg\"></center>\n",
        "\n",
        "<i> <center>Figura: El perceptron, w representa los pesos </center></i>\n",
        "\n",
        "Utilizaremos \"Dense\" para definir layers completamente conectados entre si, adicionalmente, podemos especificar el número de neuronas por layer en Keras, como veremos a continuación.\n",
        "\n",
        "De igual forma puede escogerse la función de activación, en la documentación se puede ver todas las funciones que ofrece Keras, escojamos una ReLu en este problema.\n",
        "\n",
        "https://keras.io/activations/\n",
        "\n",
        "<center><img src = \"res/layer.jpg\"></center>\n",
        "\n",
        "<i> <center>Figura: Concepto de layer </center></i>\n",
        "\n",
        "La arquitectura que planteamos para resolver este problema, es la siguiente:\n",
        "\n",
        "## Entrada de 8 variables (conjunto X, observar X.shape)\n",
        "## Primer capa oculta (hidden layer) con 12 nodos (neuronas) y función de activación ReLu.\n",
        "## Segunda capa oculta con 8 nodos y activación ReLu\n",
        "## Capa de salida con 1 nodo y activación Sigmoide\n",
        "\n",
        "Si se generan dudas acerca de qué es una función ReLu y una Sigmoide y cómo funcionan, a continuación hay documentación genérica sobre éstas.\n",
        "\n",
        "https://es.wikipedia.org/wiki/Funci%C3%B3n_sigmoide\n",
        "https://es.wikipedia.org/wiki/Rectificador_(redes_neuronales)\n",
        "\n",
        "## ¡Comencemos!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "No78XE5n94rS",
        "colab_type": "code",
        "outputId": "13bfc2f5-2f89-4528-92fc-78e464b2193b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "#definir el modelo, será secuencial dado que se pondrá un layer tras otro totalmente conectados\n",
        "model = Sequential()\n",
        "#Capa de entrada y primer capa oculta(ambos se ejecutan con esta instrucción)\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "#Segunda capa oculta\n",
        "model.add(Dense(8, activation='relu'))\n",
        "#Capa de salida\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0827 19:20:02.923517 140305150691200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0827 19:20:02.988620 140305150691200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0827 19:20:02.998100 140305150691200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C34XTo3B94rZ",
        "colab_type": "text"
      },
      "source": [
        "Una vez definido el modelo en Keras, lo compilamos.\n",
        "\n",
        "Esto permite un entrenamiento eficiente del modelo y una optimización del mismo. Adicionalmente, hay que escoger una función de pérdida. A continuación, en la documentación se muestra todas las disponibles en Keras.\n",
        "\n",
        "https://keras.io/losses/\n",
        "\n",
        "Ahora, escogemos la función de pérdida de entropía cruzada binaria (\"binary_crossentropy\").\n",
        "\n",
        "Por otro lado, el optimizador escogido será \"adam\". Una breve explicación aquí.\n",
        "\n",
        "https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2D8oOli94rc",
        "colab_type": "code",
        "outputId": "c4c29cbb-3de8-4b8e-9453-536d5bdc95d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0827 19:20:09.015821 140305150691200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0827 19:20:09.049768 140305150691200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0827 19:20:09.057107 140305150691200 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlhuQre594rj",
        "colab_type": "text"
      },
      "source": [
        "Una vez compilado, hay que ejecutarlo sobre los datos.\n",
        "\n",
        "El proceso de entrenamiento correrá sobre los datos un número determinado de veces, cada vez que realice una iteración, ese tiempo gastado, será un \"epoch\".\n",
        "\n",
        "Escojamos el número de epochs para nuestro entrenamiento, en este caso, definamos epochs = 150. Puedes probar con 100, 200, 500, etc. \n",
        "\n",
        "Ahora, antes de actualizar el valor de los pesos, el modelo debe pasar por varios datos, ese número de filas de datos que utilice, lo definimos con batch_size, para el caso particular utilicemos 10 (por tanto cada 10 filas que recorra el modelo en el dataset, actualizará los pesos de las neuronas).\n",
        "\n",
        "Esta configuración puede ser sometida a ensayo y error y btenerse mejores o peores resultados,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "IPHxgSw194rm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X, y, epochs=150, batch_size=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8z8RJYTz94rt",
        "colab_type": "text"
      },
      "source": [
        "La precisión del modelo varía en cada epoch, en promedio se puede decir que es de 0.77.\n",
        "\n",
        "Finalmente, realicemos algunas predicciones sobre el modelo, para ver su comportamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czvemZ0r94rw",
        "colab_type": "code",
        "outputId": "88951dde-4c70-47d7-baa6-d66a17dab338",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "predictions = model.predict_classes(X)\n",
        "for i in range(10):\n",
        "    print('%s => %d (expected %d)' % (X[i].tolist(), predictions[i], y[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0] => 0 (expected 1)\n",
            "[1.0, 85.0, 66.0, 29.0, 0.0, 26.6, 0.351, 31.0] => 0 (expected 0)\n",
            "[8.0, 183.0, 64.0, 0.0, 0.0, 23.3, 0.672, 32.0] => 1 (expected 1)\n",
            "[1.0, 89.0, 66.0, 23.0, 94.0, 28.1, 0.167, 21.0] => 0 (expected 0)\n",
            "[0.0, 137.0, 40.0, 35.0, 168.0, 43.1, 2.288, 33.0] => 1 (expected 1)\n",
            "[5.0, 116.0, 74.0, 0.0, 0.0, 25.6, 0.201, 30.0] => 0 (expected 0)\n",
            "[3.0, 78.0, 50.0, 32.0, 88.0, 31.0, 0.248, 26.0] => 0 (expected 1)\n",
            "[10.0, 115.0, 0.0, 0.0, 0.0, 35.3, 0.134, 29.0] => 1 (expected 0)\n",
            "[2.0, 197.0, 70.0, 45.0, 543.0, 30.5, 0.158, 53.0] => 1 (expected 1)\n",
            "[8.0, 125.0, 96.0, 0.0, 0.0, 0.0, 0.232, 54.0] => 0 (expected 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1TD9XDT94r3",
        "colab_type": "text"
      },
      "source": [
        "Para los primeros 10 datos, el modelo erró en la predicción de 3 de ellos, lo que da una precisión del 70%, no alejada de la realidad."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRYfxCh194r6",
        "colab_type": "text"
      },
      "source": [
        "# Tarea:\n",
        "\n",
        "Formule un modelo de clasificación supervisada y un modelo de clasificación no supervisado, haciendo uso del dataset que se encuentra en la carpeta \"dataset tarea\".\n",
        "\n",
        "Debe presentar junto a estos, sus respectivas métricas de desempeño."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6y7PO56Se0iS",
        "colab_type": "text"
      },
      "source": [
        "# SOLUCIÓN TAREA REDES NEURONALES. APRENDIZAJE SUPERVISADO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcqVsaMwiOS8",
        "colab_type": "text"
      },
      "source": [
        "mushrooms = pd.read_csv(\"datos/mushrooms.csv\", sep=\",\") #Se lee dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7Z98Iozfht9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Lectura del dataset\n",
        "#mushrooms = pd.read_csv(\"datos/mushrooms.csv\", sep=\",\") \n",
        "#Lectura del dataset en Google Colab\n",
        "mushrooms = pd.read_csv(\"mushrooms.csv\", sep=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65O_TW_hiuBP",
        "colab_type": "code",
        "outputId": "573f196e-6598-44c5-f80b-4025ee043bdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "mushrooms.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>cap-shape</th>\n",
              "      <th>cap-surface</th>\n",
              "      <th>cap-color</th>\n",
              "      <th>bruises</th>\n",
              "      <th>odor</th>\n",
              "      <th>gill-attachment</th>\n",
              "      <th>gill-spacing</th>\n",
              "      <th>gill-size</th>\n",
              "      <th>gill-color</th>\n",
              "      <th>stalk-shape</th>\n",
              "      <th>stalk-root</th>\n",
              "      <th>stalk-surface-above-ring</th>\n",
              "      <th>stalk-surface-below-ring</th>\n",
              "      <th>stalk-color-above-ring</th>\n",
              "      <th>stalk-color-below-ring</th>\n",
              "      <th>veil-type</th>\n",
              "      <th>veil-color</th>\n",
              "      <th>ring-number</th>\n",
              "      <th>ring-type</th>\n",
              "      <th>spore-print-color</th>\n",
              "      <th>population</th>\n",
              "      <th>habitat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>p</td>\n",
              "      <td>x</td>\n",
              "      <td>s</td>\n",
              "      <td>n</td>\n",
              "      <td>t</td>\n",
              "      <td>p</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>n</td>\n",
              "      <td>k</td>\n",
              "      <td>e</td>\n",
              "      <td>e</td>\n",
              "      <td>s</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>k</td>\n",
              "      <td>s</td>\n",
              "      <td>u</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>e</td>\n",
              "      <td>x</td>\n",
              "      <td>s</td>\n",
              "      <td>y</td>\n",
              "      <td>t</td>\n",
              "      <td>a</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>b</td>\n",
              "      <td>k</td>\n",
              "      <td>e</td>\n",
              "      <td>c</td>\n",
              "      <td>s</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>e</td>\n",
              "      <td>b</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>t</td>\n",
              "      <td>l</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>b</td>\n",
              "      <td>n</td>\n",
              "      <td>e</td>\n",
              "      <td>c</td>\n",
              "      <td>s</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>p</td>\n",
              "      <td>x</td>\n",
              "      <td>y</td>\n",
              "      <td>w</td>\n",
              "      <td>t</td>\n",
              "      <td>p</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>e</td>\n",
              "      <td>e</td>\n",
              "      <td>s</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>k</td>\n",
              "      <td>s</td>\n",
              "      <td>u</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>e</td>\n",
              "      <td>x</td>\n",
              "      <td>s</td>\n",
              "      <td>g</td>\n",
              "      <td>f</td>\n",
              "      <td>n</td>\n",
              "      <td>f</td>\n",
              "      <td>w</td>\n",
              "      <td>b</td>\n",
              "      <td>k</td>\n",
              "      <td>t</td>\n",
              "      <td>e</td>\n",
              "      <td>s</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>e</td>\n",
              "      <td>n</td>\n",
              "      <td>a</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  class cap-shape cap-surface  ... spore-print-color population habitat\n",
              "0     p         x           s  ...                 k          s       u\n",
              "1     e         x           s  ...                 n          n       g\n",
              "2     e         b           s  ...                 n          n       m\n",
              "3     p         x           y  ...                 k          s       u\n",
              "4     e         x           s  ...                 n          a       g\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icbDhprhkBnr",
        "colab_type": "text"
      },
      "source": [
        "Como la red analalizó datos numéricos, convertimos los datos a números según su código ASCII\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMYaEWdGjZvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for column in mushrooms.columns:\n",
        "    mushrooms[column] = [ord(row) for row in mushrooms[column]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za-svn1ZlgJa",
        "colab_type": "text"
      },
      "source": [
        "Ahora los datos son numéricos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfA6qC4OlRjE",
        "colab_type": "code",
        "outputId": "94d6abdb-40a1-49ef-906f-eefd3a7b52ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "mushrooms.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>cap-shape</th>\n",
              "      <th>cap-surface</th>\n",
              "      <th>cap-color</th>\n",
              "      <th>bruises</th>\n",
              "      <th>odor</th>\n",
              "      <th>gill-attachment</th>\n",
              "      <th>gill-spacing</th>\n",
              "      <th>gill-size</th>\n",
              "      <th>gill-color</th>\n",
              "      <th>stalk-shape</th>\n",
              "      <th>stalk-root</th>\n",
              "      <th>stalk-surface-above-ring</th>\n",
              "      <th>stalk-surface-below-ring</th>\n",
              "      <th>stalk-color-above-ring</th>\n",
              "      <th>stalk-color-below-ring</th>\n",
              "      <th>veil-type</th>\n",
              "      <th>veil-color</th>\n",
              "      <th>ring-number</th>\n",
              "      <th>ring-type</th>\n",
              "      <th>spore-print-color</th>\n",
              "      <th>population</th>\n",
              "      <th>habitat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>112</td>\n",
              "      <td>120</td>\n",
              "      <td>115</td>\n",
              "      <td>110</td>\n",
              "      <td>116</td>\n",
              "      <td>112</td>\n",
              "      <td>102</td>\n",
              "      <td>99</td>\n",
              "      <td>110</td>\n",
              "      <td>107</td>\n",
              "      <td>101</td>\n",
              "      <td>101</td>\n",
              "      <td>115</td>\n",
              "      <td>115</td>\n",
              "      <td>119</td>\n",
              "      <td>119</td>\n",
              "      <td>112</td>\n",
              "      <td>119</td>\n",
              "      <td>111</td>\n",
              "      <td>112</td>\n",
              "      <td>107</td>\n",
              "      <td>115</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>101</td>\n",
              "      <td>120</td>\n",
              "      <td>115</td>\n",
              "      <td>121</td>\n",
              "      <td>116</td>\n",
              "      <td>97</td>\n",
              "      <td>102</td>\n",
              "      <td>99</td>\n",
              "      <td>98</td>\n",
              "      <td>107</td>\n",
              "      <td>101</td>\n",
              "      <td>99</td>\n",
              "      <td>115</td>\n",
              "      <td>115</td>\n",
              "      <td>119</td>\n",
              "      <td>119</td>\n",
              "      <td>112</td>\n",
              "      <td>119</td>\n",
              "      <td>111</td>\n",
              "      <td>112</td>\n",
              "      <td>110</td>\n",
              "      <td>110</td>\n",
              "      <td>103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>101</td>\n",
              "      <td>98</td>\n",
              "      <td>115</td>\n",
              "      <td>119</td>\n",
              "      <td>116</td>\n",
              "      <td>108</td>\n",
              "      <td>102</td>\n",
              "      <td>99</td>\n",
              "      <td>98</td>\n",
              "      <td>110</td>\n",
              "      <td>101</td>\n",
              "      <td>99</td>\n",
              "      <td>115</td>\n",
              "      <td>115</td>\n",
              "      <td>119</td>\n",
              "      <td>119</td>\n",
              "      <td>112</td>\n",
              "      <td>119</td>\n",
              "      <td>111</td>\n",
              "      <td>112</td>\n",
              "      <td>110</td>\n",
              "      <td>110</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>112</td>\n",
              "      <td>120</td>\n",
              "      <td>121</td>\n",
              "      <td>119</td>\n",
              "      <td>116</td>\n",
              "      <td>112</td>\n",
              "      <td>102</td>\n",
              "      <td>99</td>\n",
              "      <td>110</td>\n",
              "      <td>110</td>\n",
              "      <td>101</td>\n",
              "      <td>101</td>\n",
              "      <td>115</td>\n",
              "      <td>115</td>\n",
              "      <td>119</td>\n",
              "      <td>119</td>\n",
              "      <td>112</td>\n",
              "      <td>119</td>\n",
              "      <td>111</td>\n",
              "      <td>112</td>\n",
              "      <td>107</td>\n",
              "      <td>115</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>101</td>\n",
              "      <td>120</td>\n",
              "      <td>115</td>\n",
              "      <td>103</td>\n",
              "      <td>102</td>\n",
              "      <td>110</td>\n",
              "      <td>102</td>\n",
              "      <td>119</td>\n",
              "      <td>98</td>\n",
              "      <td>107</td>\n",
              "      <td>116</td>\n",
              "      <td>101</td>\n",
              "      <td>115</td>\n",
              "      <td>115</td>\n",
              "      <td>119</td>\n",
              "      <td>119</td>\n",
              "      <td>112</td>\n",
              "      <td>119</td>\n",
              "      <td>111</td>\n",
              "      <td>101</td>\n",
              "      <td>110</td>\n",
              "      <td>97</td>\n",
              "      <td>103</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   class  cap-shape  cap-surface  ...  spore-print-color  population  habitat\n",
              "0    112        120          115  ...                107         115      117\n",
              "1    101        120          115  ...                110         110      103\n",
              "2    101         98          115  ...                110         110      109\n",
              "3    112        120          121  ...                107         115      117\n",
              "4    101        120          115  ...                110          97      103\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SulW46-wphmF",
        "colab_type": "text"
      },
      "source": [
        "Se reduce los outputs de las variables de 112 y 101 a valores que arroja la red neuronal (0,1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ofo8zK5mhzU",
        "colab_type": "code",
        "outputId": "90c73a4e-ae33-40fd-b533-ad3278e450fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "X_mushrooms = mushrooms.drop('class', axis=1)\n",
        "y_mushrooms = mushrooms['class']\n",
        "\n",
        "lenght = (y_mushrooms.shape)[0]\n",
        "for i in range(0,lenght):\n",
        "  if y_mushrooms[i] == 112: #Categoria 'p'\n",
        "    y_mushrooms[i] = 1\n",
        "  if y_mushrooms[i] == 101: #Categoria 'e'\n",
        "    y_mushrooms[i] = 0\n",
        "\n",
        "y_mushrooms.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1\n",
              "1    0\n",
              "2    0\n",
              "3    1\n",
              "4    0\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoQ8y6JcxtJi",
        "colab_type": "code",
        "outputId": "19656e74-a741-4606-f0a9-2deb8e39948e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "X_mushrooms.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cap-shape</th>\n",
              "      <th>cap-surface</th>\n",
              "      <th>cap-color</th>\n",
              "      <th>bruises</th>\n",
              "      <th>odor</th>\n",
              "      <th>gill-attachment</th>\n",
              "      <th>gill-spacing</th>\n",
              "      <th>gill-size</th>\n",
              "      <th>gill-color</th>\n",
              "      <th>stalk-shape</th>\n",
              "      <th>stalk-root</th>\n",
              "      <th>stalk-surface-above-ring</th>\n",
              "      <th>stalk-surface-below-ring</th>\n",
              "      <th>stalk-color-above-ring</th>\n",
              "      <th>stalk-color-below-ring</th>\n",
              "      <th>veil-type</th>\n",
              "      <th>veil-color</th>\n",
              "      <th>ring-number</th>\n",
              "      <th>ring-type</th>\n",
              "      <th>spore-print-color</th>\n",
              "      <th>population</th>\n",
              "      <th>habitat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>120</td>\n",
              "      <td>115</td>\n",
              "      <td>110</td>\n",
              "      <td>116</td>\n",
              "      <td>112</td>\n",
              "      <td>102</td>\n",
              "      <td>99</td>\n",
              "      <td>110</td>\n",
              "      <td>107</td>\n",
              "      <td>101</td>\n",
              "      <td>101</td>\n",
              "      <td>115</td>\n",
              "      <td>115</td>\n",
              "      <td>119</td>\n",
              "      <td>119</td>\n",
              "      <td>112</td>\n",
              "      <td>119</td>\n",
              "      <td>111</td>\n",
              "      <td>112</td>\n",
              "      <td>107</td>\n",
              "      <td>115</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>120</td>\n",
              "      <td>115</td>\n",
              "      <td>121</td>\n",
              "      <td>116</td>\n",
              "      <td>97</td>\n",
              "      <td>102</td>\n",
              "      <td>99</td>\n",
              "      <td>98</td>\n",
              "      <td>107</td>\n",
              "      <td>101</td>\n",
              "      <td>99</td>\n",
              "      <td>115</td>\n",
              "      <td>115</td>\n",
              "      <td>119</td>\n",
              "      <td>119</td>\n",
              "      <td>112</td>\n",
              "      <td>119</td>\n",
              "      <td>111</td>\n",
              "      <td>112</td>\n",
              "      <td>110</td>\n",
              "      <td>110</td>\n",
              "      <td>103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>98</td>\n",
              "      <td>115</td>\n",
              "      <td>119</td>\n",
              "      <td>116</td>\n",
              "      <td>108</td>\n",
              "      <td>102</td>\n",
              "      <td>99</td>\n",
              "      <td>98</td>\n",
              "      <td>110</td>\n",
              "      <td>101</td>\n",
              "      <td>99</td>\n",
              "      <td>115</td>\n",
              "      <td>115</td>\n",
              "      <td>119</td>\n",
              "      <td>119</td>\n",
              "      <td>112</td>\n",
              "      <td>119</td>\n",
              "      <td>111</td>\n",
              "      <td>112</td>\n",
              "      <td>110</td>\n",
              "      <td>110</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>120</td>\n",
              "      <td>121</td>\n",
              "      <td>119</td>\n",
              "      <td>116</td>\n",
              "      <td>112</td>\n",
              "      <td>102</td>\n",
              "      <td>99</td>\n",
              "      <td>110</td>\n",
              "      <td>110</td>\n",
              "      <td>101</td>\n",
              "      <td>101</td>\n",
              "      <td>115</td>\n",
              "      <td>115</td>\n",
              "      <td>119</td>\n",
              "      <td>119</td>\n",
              "      <td>112</td>\n",
              "      <td>119</td>\n",
              "      <td>111</td>\n",
              "      <td>112</td>\n",
              "      <td>107</td>\n",
              "      <td>115</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>120</td>\n",
              "      <td>115</td>\n",
              "      <td>103</td>\n",
              "      <td>102</td>\n",
              "      <td>110</td>\n",
              "      <td>102</td>\n",
              "      <td>119</td>\n",
              "      <td>98</td>\n",
              "      <td>107</td>\n",
              "      <td>116</td>\n",
              "      <td>101</td>\n",
              "      <td>115</td>\n",
              "      <td>115</td>\n",
              "      <td>119</td>\n",
              "      <td>119</td>\n",
              "      <td>112</td>\n",
              "      <td>119</td>\n",
              "      <td>111</td>\n",
              "      <td>101</td>\n",
              "      <td>110</td>\n",
              "      <td>97</td>\n",
              "      <td>103</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cap-shape  cap-surface  cap-color  ...  spore-print-color  population  habitat\n",
              "0        120          115        110  ...                107         115      117\n",
              "1        120          115        121  ...                110         110      103\n",
              "2         98          115        119  ...                110         110      109\n",
              "3        120          121        119  ...                107         115      117\n",
              "4        120          115        103  ...                110          97      103\n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 429
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OexgSDTzrJ2Z",
        "colab_type": "code",
        "outputId": "6b4f2e78-c5ce-4e79-e367-49ca9ef4dea6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Serciorarse de que todos los datasets tengan el mismo número de registros\n",
        "print(mushrooms.shape)\n",
        "print(y_mushrooms.shape)\n",
        "print(X_mushrooms.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8124, 23)\n",
            "(8124,)\n",
            "(8124, 22)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYgNyT2xtRnz",
        "colab_type": "text"
      },
      "source": [
        "**ARQUITECTURA ~ADIVINADA~ PLANTEADA PARA LA RED:**\n",
        "\n",
        "1. **Entrada de 22 variables (conjunto X, observar X.shape)**\n",
        "\n",
        "2. **Primer capa oculta (hidden layer) con 45 nodos (neuronas) y función de activación ReLu.**\n",
        "\n",
        "3. **Segunda capa oculta con 31 nodos y activación ReLu**\n",
        "\n",
        "4. **Capa de salida con 1 nodo y activación Sigmoide**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxzIbVixuAWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#definir el modelo, será secuencial dado que se pondrá un layer tras otro totalmente conectados\n",
        "model6 = Sequential()\n",
        "#Capa de entrada y primer capa oculta(ambos se ejecutan con esta instrucción)\n",
        "model6.add(Dense(45, input_dim=22, activation='relu'))\n",
        "#Segunda capa oculta\n",
        "model6.add(Dense(31, activation='relu'))\n",
        "#Capa de salida\n",
        "model6.add(Dense(1, activation='sigmoid'))\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSzN-ABJuz-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model6.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nfh9mc-mmwBZ",
        "colab_type": "text"
      },
      "source": [
        "#### este titulo tiene como único propósito plegar la siguiente celda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE4wD0-4u4UO",
        "colab_type": "code",
        "outputId": "bcae7b98-5db1-4a96-85a4-8c34528481a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "model6.fit(X_mushrooms, y_mushrooms, epochs=150, batch_size=30)\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "8124/8124 [==============================] - 2s 197us/step - loss: 0.6463 - acc: 0.7779\n",
            "Epoch 2/150\n",
            "8124/8124 [==============================] - 0s 50us/step - loss: 0.4063 - acc: 0.8460\n",
            "Epoch 3/150\n",
            "8124/8124 [==============================] - 0s 48us/step - loss: 0.3051 - acc: 0.8856\n",
            "Epoch 4/150\n",
            "8124/8124 [==============================] - 0s 48us/step - loss: 0.2759 - acc: 0.8999\n",
            "Epoch 5/150\n",
            "8124/8124 [==============================] - 0s 44us/step - loss: 0.2837 - acc: 0.8945\n",
            "Epoch 6/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.2452 - acc: 0.9098\n",
            "Epoch 7/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.2483 - acc: 0.9117\n",
            "Epoch 8/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.2487 - acc: 0.9106\n",
            "Epoch 9/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.2178 - acc: 0.9209\n",
            "Epoch 10/150\n",
            "8124/8124 [==============================] - 0s 48us/step - loss: 0.2170 - acc: 0.9217\n",
            "Epoch 11/150\n",
            "8124/8124 [==============================] - 0s 44us/step - loss: 0.2244 - acc: 0.9159\n",
            "Epoch 12/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.1946 - acc: 0.9266\n",
            "Epoch 13/150\n",
            "8124/8124 [==============================] - 0s 44us/step - loss: 0.2243 - acc: 0.9218\n",
            "Epoch 14/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.2081 - acc: 0.9243\n",
            "Epoch 15/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.1962 - acc: 0.9287\n",
            "Epoch 16/150\n",
            "8124/8124 [==============================] - 0s 49us/step - loss: 0.2187 - acc: 0.9222\n",
            "Epoch 17/150\n",
            "8124/8124 [==============================] - 0s 48us/step - loss: 0.1948 - acc: 0.9275\n",
            "Epoch 18/150\n",
            "8124/8124 [==============================] - 0s 49us/step - loss: 0.1839 - acc: 0.9322\n",
            "Epoch 19/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.1846 - acc: 0.9301\n",
            "Epoch 20/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.1778 - acc: 0.9334\n",
            "Epoch 21/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.1769 - acc: 0.9346\n",
            "Epoch 22/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.1727 - acc: 0.9349\n",
            "Epoch 23/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.1701 - acc: 0.9382\n",
            "Epoch 24/150\n",
            "8124/8124 [==============================] - 0s 45us/step - loss: 0.1749 - acc: 0.9322\n",
            "Epoch 25/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.1647 - acc: 0.9375\n",
            "Epoch 26/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.1368 - acc: 0.9472\n",
            "Epoch 27/150\n",
            "8124/8124 [==============================] - 0s 45us/step - loss: 0.1479 - acc: 0.9444\n",
            "Epoch 28/150\n",
            "8124/8124 [==============================] - 0s 45us/step - loss: 0.1581 - acc: 0.9410\n",
            "Epoch 29/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.1310 - acc: 0.9501\n",
            "Epoch 30/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.1186 - acc: 0.9554\n",
            "Epoch 31/150\n",
            "8124/8124 [==============================] - 0s 48us/step - loss: 0.1269 - acc: 0.9526\n",
            "Epoch 32/150\n",
            "8124/8124 [==============================] - 0s 48us/step - loss: 0.1313 - acc: 0.9520\n",
            "Epoch 33/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.1457 - acc: 0.9462\n",
            "Epoch 34/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.1237 - acc: 0.9540\n",
            "Epoch 35/150\n",
            "8124/8124 [==============================] - 0s 48us/step - loss: 0.1214 - acc: 0.9530\n",
            "Epoch 36/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.1212 - acc: 0.9535\n",
            "Epoch 37/150\n",
            "8124/8124 [==============================] - 0s 49us/step - loss: 0.1257 - acc: 0.9505\n",
            "Epoch 38/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.1006 - acc: 0.9632\n",
            "Epoch 39/150\n",
            "8124/8124 [==============================] - 0s 50us/step - loss: 0.0991 - acc: 0.9628\n",
            "Epoch 40/150\n",
            "8124/8124 [==============================] - 0s 49us/step - loss: 0.1148 - acc: 0.9586\n",
            "Epoch 41/150\n",
            "8124/8124 [==============================] - 0s 48us/step - loss: 0.0988 - acc: 0.9645\n",
            "Epoch 42/150\n",
            "8124/8124 [==============================] - 0s 51us/step - loss: 0.1044 - acc: 0.9588\n",
            "Epoch 43/150\n",
            "8124/8124 [==============================] - 0s 48us/step - loss: 0.1236 - acc: 0.9548\n",
            "Epoch 44/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.0825 - acc: 0.9692\n",
            "Epoch 45/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.0775 - acc: 0.9721\n",
            "Epoch 46/150\n",
            "8124/8124 [==============================] - 0s 45us/step - loss: 0.1070 - acc: 0.9589\n",
            "Epoch 47/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0787 - acc: 0.9714\n",
            "Epoch 48/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0808 - acc: 0.9711\n",
            "Epoch 49/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.0809 - acc: 0.9703\n",
            "Epoch 50/150\n",
            "8124/8124 [==============================] - 0s 48us/step - loss: 0.0868 - acc: 0.9660\n",
            "Epoch 51/150\n",
            "8124/8124 [==============================] - 0s 48us/step - loss: 0.0688 - acc: 0.9742\n",
            "Epoch 52/150\n",
            "8124/8124 [==============================] - 0s 48us/step - loss: 0.0722 - acc: 0.9735\n",
            "Epoch 53/150\n",
            "8124/8124 [==============================] - 0s 48us/step - loss: 0.0868 - acc: 0.9696\n",
            "Epoch 54/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.0765 - acc: 0.9717\n",
            "Epoch 55/150\n",
            "8124/8124 [==============================] - 0s 45us/step - loss: 0.0829 - acc: 0.9681\n",
            "Epoch 56/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0762 - acc: 0.9732\n",
            "Epoch 57/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0562 - acc: 0.9803\n",
            "Epoch 58/150\n",
            "8124/8124 [==============================] - 0s 45us/step - loss: 0.0684 - acc: 0.9758\n",
            "Epoch 59/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0590 - acc: 0.9798\n",
            "Epoch 60/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.0693 - acc: 0.9740\n",
            "Epoch 61/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.0612 - acc: 0.9785\n",
            "Epoch 62/150\n",
            "8124/8124 [==============================] - 0s 48us/step - loss: 0.0478 - acc: 0.9841\n",
            "Epoch 63/150\n",
            "8124/8124 [==============================] - 0s 54us/step - loss: 0.0553 - acc: 0.9807\n",
            "Epoch 64/150\n",
            "8124/8124 [==============================] - 0s 49us/step - loss: 0.0679 - acc: 0.9777\n",
            "Epoch 65/150\n",
            "8124/8124 [==============================] - 0s 50us/step - loss: 0.0432 - acc: 0.9852\n",
            "Epoch 66/150\n",
            "8124/8124 [==============================] - 0s 48us/step - loss: 0.0619 - acc: 0.9782\n",
            "Epoch 67/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0450 - acc: 0.9849\n",
            "Epoch 68/150\n",
            "8124/8124 [==============================] - 0s 45us/step - loss: 0.0474 - acc: 0.9838\n",
            "Epoch 69/150\n",
            "8124/8124 [==============================] - 0s 45us/step - loss: 0.0797 - acc: 0.9717\n",
            "Epoch 70/150\n",
            "8124/8124 [==============================] - 0s 50us/step - loss: 0.0457 - acc: 0.9842\n",
            "Epoch 71/150\n",
            "8124/8124 [==============================] - 0s 48us/step - loss: 0.0464 - acc: 0.9842\n",
            "Epoch 72/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.0454 - acc: 0.9851\n",
            "Epoch 73/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.0657 - acc: 0.9782\n",
            "Epoch 74/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0425 - acc: 0.9855\n",
            "Epoch 75/150\n",
            "8124/8124 [==============================] - 0s 49us/step - loss: 0.0685 - acc: 0.9756\n",
            "Epoch 76/150\n",
            "8124/8124 [==============================] - 0s 51us/step - loss: 0.0621 - acc: 0.9775\n",
            "Epoch 77/150\n",
            "8124/8124 [==============================] - 0s 48us/step - loss: 0.0461 - acc: 0.9826\n",
            "Epoch 78/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0674 - acc: 0.9753\n",
            "Epoch 79/150\n",
            "8124/8124 [==============================] - 0s 45us/step - loss: 0.0462 - acc: 0.9838\n",
            "Epoch 80/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.0367 - acc: 0.9888\n",
            "Epoch 81/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0375 - acc: 0.9871\n",
            "Epoch 82/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.0501 - acc: 0.9825\n",
            "Epoch 83/150\n",
            "8124/8124 [==============================] - 0s 49us/step - loss: 0.0391 - acc: 0.9871\n",
            "Epoch 84/150\n",
            "8124/8124 [==============================] - 0s 48us/step - loss: 0.0463 - acc: 0.9835\n",
            "Epoch 85/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.0375 - acc: 0.9868\n",
            "Epoch 86/150\n",
            "8124/8124 [==============================] - 0s 48us/step - loss: 0.0496 - acc: 0.9838\n",
            "Epoch 87/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.0572 - acc: 0.9804\n",
            "Epoch 88/150\n",
            "8124/8124 [==============================] - 0s 48us/step - loss: 0.0497 - acc: 0.9823\n",
            "Epoch 89/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.0487 - acc: 0.9830\n",
            "Epoch 90/150\n",
            "8124/8124 [==============================] - 0s 49us/step - loss: 0.0472 - acc: 0.9833\n",
            "Epoch 91/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.0544 - acc: 0.9817\n",
            "Epoch 92/150\n",
            "8124/8124 [==============================] - 0s 45us/step - loss: 0.0509 - acc: 0.9812\n",
            "Epoch 93/150\n",
            "8124/8124 [==============================] - 0s 48us/step - loss: 0.0280 - acc: 0.9903\n",
            "Epoch 94/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.0470 - acc: 0.9855\n",
            "Epoch 95/150\n",
            "8124/8124 [==============================] - 0s 51us/step - loss: 0.0342 - acc: 0.9895\n",
            "Epoch 96/150\n",
            "8124/8124 [==============================] - 0s 45us/step - loss: 0.0308 - acc: 0.9899\n",
            "Epoch 97/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0441 - acc: 0.9847\n",
            "Epoch 98/150\n",
            "8124/8124 [==============================] - 0s 45us/step - loss: 0.0370 - acc: 0.9867\n",
            "Epoch 99/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0498 - acc: 0.9817\n",
            "Epoch 100/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0332 - acc: 0.9877\n",
            "Epoch 101/150\n",
            "8124/8124 [==============================] - 0s 48us/step - loss: 0.0647 - acc: 0.9778\n",
            "Epoch 102/150\n",
            "8124/8124 [==============================] - 0s 48us/step - loss: 0.0310 - acc: 0.9894\n",
            "Epoch 103/150\n",
            "8124/8124 [==============================] - 0s 49us/step - loss: 0.0348 - acc: 0.9867\n",
            "Epoch 104/150\n",
            "8124/8124 [==============================] - 0s 49us/step - loss: 0.0294 - acc: 0.9897\n",
            "Epoch 105/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0425 - acc: 0.9855\n",
            "Epoch 106/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.0564 - acc: 0.9791\n",
            "Epoch 107/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.0401 - acc: 0.9857\n",
            "Epoch 108/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0432 - acc: 0.9840\n",
            "Epoch 109/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0282 - acc: 0.9908\n",
            "Epoch 110/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0679 - acc: 0.9758\n",
            "Epoch 111/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0355 - acc: 0.9871\n",
            "Epoch 112/150\n",
            "8124/8124 [==============================] - 0s 48us/step - loss: 0.0291 - acc: 0.9898\n",
            "Epoch 113/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0271 - acc: 0.9890\n",
            "Epoch 114/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0487 - acc: 0.9839\n",
            "Epoch 115/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0337 - acc: 0.9881\n",
            "Epoch 116/150\n",
            "8124/8124 [==============================] - 0s 48us/step - loss: 0.0332 - acc: 0.9878\n",
            "Epoch 117/150\n",
            "8124/8124 [==============================] - 0s 50us/step - loss: 0.0628 - acc: 0.9781\n",
            "Epoch 118/150\n",
            "8124/8124 [==============================] - 0s 49us/step - loss: 0.0474 - acc: 0.9835\n",
            "Epoch 119/150\n",
            "8124/8124 [==============================] - 0s 50us/step - loss: 0.0281 - acc: 0.9890\n",
            "Epoch 120/150\n",
            "8124/8124 [==============================] - 0s 48us/step - loss: 0.1176 - acc: 0.9599\n",
            "Epoch 121/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.0603 - acc: 0.9759\n",
            "Epoch 122/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.0531 - acc: 0.9786\n",
            "Epoch 123/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0465 - acc: 0.9822\n",
            "Epoch 124/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.0481 - acc: 0.9818\n",
            "Epoch 125/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.0643 - acc: 0.9759\n",
            "Epoch 126/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.0350 - acc: 0.9874\n",
            "Epoch 127/150\n",
            "8124/8124 [==============================] - 0s 45us/step - loss: 0.0423 - acc: 0.9840\n",
            "Epoch 128/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0340 - acc: 0.9886\n",
            "Epoch 129/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0456 - acc: 0.9829\n",
            "Epoch 130/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0383 - acc: 0.9866\n",
            "Epoch 131/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0563 - acc: 0.9786\n",
            "Epoch 132/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.0444 - acc: 0.9842\n",
            "Epoch 133/150\n",
            "8124/8124 [==============================] - 0s 48us/step - loss: 0.0518 - acc: 0.9813\n",
            "Epoch 134/150\n",
            "8124/8124 [==============================] - 0s 48us/step - loss: 0.0341 - acc: 0.9871\n",
            "Epoch 135/150\n",
            "8124/8124 [==============================] - 0s 45us/step - loss: 0.0324 - acc: 0.9876\n",
            "Epoch 136/150\n",
            "8124/8124 [==============================] - 0s 44us/step - loss: 0.0400 - acc: 0.9870\n",
            "Epoch 137/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.0291 - acc: 0.9894\n",
            "Epoch 138/150\n",
            "8124/8124 [==============================] - 0s 48us/step - loss: 0.0251 - acc: 0.9910\n",
            "Epoch 139/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0480 - acc: 0.9815\n",
            "Epoch 140/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.0320 - acc: 0.9883\n",
            "Epoch 141/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0733 - acc: 0.9761\n",
            "Epoch 142/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.0303 - acc: 0.9882\n",
            "Epoch 143/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.0329 - acc: 0.9877\n",
            "Epoch 144/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0267 - acc: 0.9902\n",
            "Epoch 145/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0246 - acc: 0.9914\n",
            "Epoch 146/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0347 - acc: 0.9861\n",
            "Epoch 147/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.0352 - acc: 0.9866\n",
            "Epoch 148/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0353 - acc: 0.9858\n",
            "Epoch 149/150\n",
            "8124/8124 [==============================] - 0s 46us/step - loss: 0.0289 - acc: 0.9884\n",
            "Epoch 150/150\n",
            "8124/8124 [==============================] - 0s 47us/step - loss: 0.0266 - acc: 0.9902\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZbrh3q8m42h",
        "colab_type": "text"
      },
      "source": [
        "#### -----------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFxlG8i5z6eC",
        "colab_type": "code",
        "outputId": "5fbfbf69-0f78-4428-b9d8-ee776d8c637d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "predictions_Shrooms = model6.predict_classes(X_mushrooms)\n",
        "for i in range(10):\n",
        "    print('%d => %s (expected %s)' % (i, predictions_Shrooms[i] , y_mushrooms[i]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 => [1] (expected 1)\n",
            "1 => [0] (expected 0)\n",
            "2 => [0] (expected 0)\n",
            "3 => [1] (expected 1)\n",
            "4 => [0] (expected 0)\n",
            "5 => [0] (expected 0)\n",
            "6 => [0] (expected 0)\n",
            "7 => [0] (expected 0)\n",
            "8 => [1] (expected 1)\n",
            "9 => [0] (expected 0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "negNY_t2iF5D",
        "colab_type": "text"
      },
      "source": [
        "Para los diez primeros datos, el modelo no erró en ninguno, lo cual es una belleza de hermosura"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_VVo5tnk8p5",
        "colab_type": "text"
      },
      "source": [
        "# Modelo no supervisado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weH3KHl3oRgi",
        "colab_type": "text"
      },
      "source": [
        "Importamos librerías para poder hacer el kmeans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAdcuHpclP2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import pairwise_distances_argmin_min"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw5_W8FinK_A",
        "colab_type": "text"
      },
      "source": [
        "Usaremos dos centroides en el algoritmo de k-means para generar dos grupos diferentes, que se espera, correspondan a las clases \"p\" y \"e\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oauCCFotlkhx",
        "colab_type": "code",
        "outputId": "7fe4471e-9702-4c5b-98ef-a17fce85b638",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "kmeans = KMeans( n_clusters = 2 ).fit(X_mushrooms)\n",
        "centroides = kmeans.cluster_centers_\n",
        "\n",
        "print(centroides)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[110.94826364 112.37632884 110.11339476 109.89794472 106.40184266\n",
            "  101.98405386 102.62863218  99.49681077 110.89014883 108.654146\n",
            "   99.23812899 111.86605245 112.15946137 113.67044649 113.59390503\n",
            "  112.         119.00283487 111.09992913 109.46279235 107.66761162\n",
            "  116.34372785 103.86109142]\n",
            " [109.27419355 116.63870968 106.81290323 103.08387097 111.85806452\n",
            "  101.61290323 101.32258065 106.7483871  102.27741935 111.4516129\n",
            "   63.         111.64516129 111.57419355 115.24516129 115.2\n",
            "  112.         118.34193548 111.96774194 103.1483871  118.01290323\n",
            "  115.18387097 107.08387097]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gyjFq4RqgJ4",
        "colab_type": "text"
      },
      "source": [
        "A cada elemento se le hace una asignación a un cluster (correspondiente a una categoría) 1=p, 0=e"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30vNYKeZod1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clusters\n",
        "categoria_predicha = kmeans.predict(X_mushrooms)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_LP0e2xojb4",
        "colab_type": "code",
        "outputId": "fb005ab4-1342-4646-8c39-9bfb8b73083c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "correctas = 0\n",
        "falso_p = 0\n",
        "falso_e = 0\n",
        "verdadero_p = 0\n",
        "verdadero_e = 0\n",
        "totales = len(categoria_predicha)\n",
        "\n",
        "for i in range(totales):\n",
        "    if categoria_predicha[i] == y_mushrooms[i]:\n",
        "        correctas += 1\n",
        "    if categoria_predicha[i] == 1 and y_mushrooms[i] == 0 :\n",
        "      falso_p += 1\n",
        "    if categoria_predicha[i] == 0 and y_mushrooms[i] == 1 :\n",
        "      falso_e += 1\n",
        "    if categoria_predicha[i] == 1 and y_mushrooms[i] == 1 :\n",
        "      verdadero_p += 1\n",
        "    if categoria_predicha[i] == 0 and y_mushrooms[i] == 0 :\n",
        "      verdadero_e += 1\n",
        "        \n",
        "print(\"de %d datos asignados a un cluster, %d se asignaron a la categoria correcta.\"%( totales, correctas) )\n",
        "\n",
        "porcentaje = 100*( correctas / totales )\n",
        "print( \"El porcentaje de aciertos fue: %d\"%porcentaje  )\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "de 8124 datos asignados a un cluster, 5248 se asignaron a la categoria correcta.\n",
            "El porcentaje de aciertos fue: 64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W54Hzm0ruAxa",
        "colab_type": "text"
      },
      "source": [
        "Vamos a hacer una análisis para la categoría \"p\" (representada por 1 en el dataset)\n",
        "\n",
        "Vamos a suponer la categoría \"p\" como positivo(+) y la categoría \"e\" como negativo(-)\n",
        "\n",
        "Y así, podemos calcular métricas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39zD6TelwD_6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c11ac046-8150-491c-abd7-839aae0e10b3"
      },
      "source": [
        "precision = verdadero_p / ( verdadero_p + falso_p )\n",
        "sensibilidad = verdadero_p / ( verdadero_p + falso_e )\n",
        "especificidad = verdadero_e / ( verdadero_e + falso_p )\n",
        "F1_score = ( 2 * precision * sensibilidad ) / ( precision + sensibilidad )\n",
        "\n",
        "print(\"La precisión del modelo es: \", precision)\n",
        "print(\"La sensibilidad(Recall) del modelo es: \", sensibilidad)\n",
        "print(\"La especificidad del modelo es: \", especificidad)\n",
        "print(\"El F1-score del modelo es: \", F1_score)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "La precisión del modelo es:  0.7096774193548387\n",
            "La sensibilidad(Recall) del modelo es:  0.449438202247191\n",
            "La especificidad del modelo es:  0.8288973384030418\n",
            "El F1-score del modelo es:  0.5503439649781113\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhj8B2QqyRak",
        "colab_type": "text"
      },
      "source": [
        "### Conclusiones:\n",
        "\n",
        "1. Podemos ver que el modelo tiene una alta tendencia (0.70) a NO catalogar elementos pertenecientes 'e' como pertenecientes a 'p'\n",
        "\n",
        "2. El modelo tiene una baja (0.44) capacidad de encontrar valores de 'p'.\n",
        "\n",
        "3. La capacidad del modelo de encontrar elementos pertenecientes a 'e' es alta (0.82)\n",
        "\n",
        "4. En general, al modelo le fue regular tirando a bien (0.55)"
      ]
    }
  ]
}